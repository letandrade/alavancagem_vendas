{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Case - Alavancagem de vendas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Bilibotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geral e visualizações\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# Cluster \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Setar seed para obter resultados reproduziveis\n",
    "seed = 100\n",
    "\n",
    "# Classificação\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Regressão\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.metrics import (mean_absolute_error,mean_squared_error,mean_absolute_percentage_error,r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Importando a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar base \n",
    "base = pd.read_csv('base.csv',sep = ';', decimal = ',' , encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resumo\n",
    "print(base.shape)\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resumo\n",
    "base.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resumo\n",
    "base.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alterando os tipos das variáveis\n",
    "base['COD_CICLO'] = base['COD_CICLO'].astype('str')\n",
    "base['COD_MATERIAL'] = base['COD_MATERIAL'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizaremos apenas o período de 2018 a 2020, esse perído facilitará as análises\n",
    "# Além disso, a qtd de informações em 2021 é pequena pois contém apenas um período\n",
    "base = base[base['COD_CICLO']!= '202101']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Análise de contexto - Conhecendo as variáveis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifcando os valores únicos\n",
    "base.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifcando os valores em branco\n",
    "base.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# análise dos dados com profile\n",
    "profile_base = ProfileReport(base)\n",
    "profile_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de produtos por faixa de frequência de ciclos\n",
    "freq_mat = base.groupby(['COD_MATERIAL'],as_index=False)['COD_CICLO'].nunique()\n",
    "freq_mat = freq_mat.set_axis(['COD_MATERIAL', 'QTD_COD_CICLO'], axis=1)\n",
    "freq_mat = pd.DataFrame(freq_mat['QTD_COD_CICLO'])\n",
    "freq_mat.reset_index(inplace = True,drop = True)\n",
    "freq_mat\n",
    "\n",
    "print(freq_mat.min())\n",
    "print(freq_mat.max())\n",
    "\n",
    "plt.figure()\n",
    "freq_mat.groupby(pd.cut(freq_mat['QTD_COD_CICLO'], np.arange(0,65,10))).count().plot(kind='bar', legend=False)\n",
    "plt.title('Quantidade de materiais por faixa de frequência de ciclos')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de produtos por faixa de ticket médio de venda líquida\n",
    "ticket_mat = base.groupby(['COD_MATERIAL'],as_index=False).agg({\n",
    "    'VL_RECEITA_LIQUIDA':'sum',\n",
    "    'QT_VENDA_BRUTO':'sum'})\n",
    "ticket_mat = ticket_mat.set_axis(['COD_MATERIAL', 'VL_RECEITA_LIQUIDA','QT_VENDA_BRUTA'], axis=1)\n",
    "ticket_mat['TICKET_VENDA'] = ticket_mat['VL_RECEITA_LIQUIDA']/ticket_mat['QT_VENDA_BRUTA']\n",
    "ticket_mat = pd.DataFrame(ticket_mat['TICKET_VENDA'])\n",
    "ticket_mat.reset_index(inplace = True,drop = True)\n",
    "ticket_mat\n",
    "\n",
    "print(ticket_mat.min())\n",
    "print(ticket_mat.max())\n",
    "\n",
    "plt.figure()\n",
    "ticket_mat.groupby(pd.cut(ticket_mat['TICKET_VENDA'], np.arange(0,250,60))).count().plot(kind='bar', legend=False)\n",
    "plt.title('Quantidade de materiais por faixa de ticket médio de receita líquida')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de produtos por faixa de média de preço\n",
    "preco_mat = base.groupby(['COD_MATERIAL'],as_index=False)['VL_PRECO'].mean()\n",
    "preco_mat = preco_mat.set_axis(['COD_MATERIAL', 'VL_PRECO'], axis=1)\n",
    "preco_mat = pd.DataFrame(preco_mat['VL_PRECO'])\n",
    "preco_mat.reset_index(inplace = True,drop = True)\n",
    "preco_mat\n",
    "\n",
    "print(preco_mat.min())\n",
    "print(preco_mat.max())\n",
    "\n",
    "plt.figure()\n",
    "preco_mat.groupby(pd.cut(preco_mat['VL_PRECO'], np.arange(0,2500,500))).count().plot(kind='bar', legend=False)\n",
    "plt.title('Quantidade de materiais por faixa de média de preço')\n",
    "plt.xlabel('')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VL_RECEITA_LIQUIDA por Canal\n",
    "venda_liq_canal = base.groupby('COD_CANAL', as_index=False)['VL_RECEITA_LIQUIDA'].sum()\n",
    "venda_liq_canal = venda_liq_canal.set_axis(['COD_CANAL', 'VL_RECEITA_LIQUIDA'], axis=1, inplace=False)\n",
    "venda_liq_canal = venda_liq_canal.sort_values(by=['VL_RECEITA_LIQUIDA'],ascending=False)\n",
    "\n",
    "plt.bar(venda_liq_canal['COD_CANAL'] ,venda_liq_canal['VL_RECEITA_LIQUIDA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VL_RECEITA_LIQUIDA por Categoria\n",
    "venda_liq_categoria = base.groupby('DES_CATEGORIA_MATERIAL', as_index=False)['VL_RECEITA_LIQUIDA'].sum()\n",
    "venda_liq_categoria = venda_liq_categoria.set_axis(['DES_CATEGORIA_MATERIAL', 'VL_RECEITA_LIQUIDA'], axis=1, inplace=False)\n",
    "venda_liq_categoria = venda_liq_categoria.sort_values(by=['VL_RECEITA_LIQUIDA'],ascending=False)\n",
    "\n",
    "plt.bar(venda_liq_categoria['DES_CATEGORIA_MATERIAL'] ,venda_liq_categoria['VL_RECEITA_LIQUIDA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VL_RECEITA_LIQUIDA por marca\n",
    "venda_liq_marca = base.groupby('DES_MARCA_MATERIAL', as_index=False)['VL_RECEITA_LIQUIDA'].sum()\n",
    "venda_liq_marca = venda_liq_marca.set_axis(['DES_MARCA_MATERIAL', 'VL_RECEITA_LIQUIDA'], axis=1, inplace=False)\n",
    "venda_liq_marca = venda_liq_marca.sort_values(by=['VL_RECEITA_LIQUIDA'],ascending=False)\n",
    "\n",
    "plt.bar(venda_liq_marca['DES_MARCA_MATERIAL'] ,venda_liq_marca['VL_RECEITA_LIQUIDA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#VL_RECEITA_LIQUIDA por região\n",
    "venda_liq_regiao = base.groupby('COD_REGIAO', as_index=False)['VL_RECEITA_LIQUIDA'].sum()\n",
    "venda_liq_regiao = venda_liq_regiao.set_axis(['COD_REGIAO', 'VL_RECEITA_LIQUIDA'], axis=1, inplace=False)\n",
    "venda_liq_regiao = venda_liq_regiao.sort_values(by=['VL_RECEITA_LIQUIDA'],ascending=False)\n",
    "\n",
    "plt.bar(venda_liq_regiao['COD_REGIAO'] ,venda_liq_regiao['VL_RECEITA_LIQUIDA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QTD_VENDA por canal\n",
    "qtd_canal = base.groupby('COD_CANAL', as_index=False)['QT_VENDA_BRUTO'].sum()\n",
    "qtd_canal = qtd_canal.set_axis(['COD_CANAL', 'QT_VENDA_BRUTO'], axis=1, inplace=False)\n",
    "qtd_canal = qtd_canal.sort_values(by=['QT_VENDA_BRUTO'],ascending=False)\n",
    "\n",
    "plt.bar(qtd_canal['COD_CANAL'] ,qtd_canal['QT_VENDA_BRUTO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QTD_VENDA por categoria\n",
    "qtd_categoria = base.groupby('DES_CATEGORIA_MATERIAL', as_index=False)['QT_VENDA_BRUTO'].sum()\n",
    "qtd_categoria = qtd_categoria.set_axis(['DES_CATEGORIA_MATERIAL', 'QT_VENDA_BRUTO'], axis=1, inplace=False)\n",
    "qtd_categoria = qtd_categoria.sort_values(by=['QT_VENDA_BRUTO'],ascending=False)\n",
    "\n",
    "plt.bar(qtd_categoria['DES_CATEGORIA_MATERIAL'] ,qtd_categoria['QT_VENDA_BRUTO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QTD_VENDA por marca\n",
    "qtd_marca = base.groupby('DES_MARCA_MATERIAL', as_index=False)['QT_VENDA_BRUTO'].sum()\n",
    "qtd_marca = qtd_marca.set_axis(['DES_MARCA_MATERIAL', 'QT_VENDA_BRUTO'], axis=1, inplace=False)\n",
    "qtd_marca = qtd_marca.sort_values(by=['QT_VENDA_BRUTO'],ascending=False)\n",
    "\n",
    "plt.bar(qtd_marca['DES_MARCA_MATERIAL'] ,qtd_marca['QT_VENDA_BRUTO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QTD_VENDA por região\n",
    "qtd_regiao = base.groupby('COD_REGIAO', as_index=False)['QT_VENDA_BRUTO'].sum()\n",
    "qtd_regiao = qtd_regiao.set_axis(['COD_REGIAO', 'QT_VENDA_BRUTO'], axis=1, inplace=False)\n",
    "qtd_regiao = qtd_regiao.sort_values(by=['QT_VENDA_BRUTO'],ascending=False)\n",
    "\n",
    "plt.bar(qtd_regiao['COD_REGIAO'] ,qtd_regiao['QT_VENDA_BRUTO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Clusterização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Prepando a base de dados para o cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = base\n",
    "df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para extrair o ano\n",
    "def extrair_ano(arg):\n",
    "     return arg[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster['ANO'] = df_cluster.COD_CICLO.apply(extrair_ano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster['ANO'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = pd.pivot_table(df_cluster, values = ['QT_VENDA_BRUTO','QT_DEVOLUCAO','VL_RECEITA_BRUTA','VL_RECEITA_LIQUIDA'],index = ['COD_MATERIAL'],\n",
    "            columns = ['ANO'], aggfunc = np.sum, fill_value=0)\n",
    "    \n",
    "df_cluster.reset_index(inplace=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renomear\n",
    "df_cluster = df_cluster.set_axis(['COD_MATERIAL','QT_DEVOLUCAO_2018','QT_DEVOLUCAO_2019','QT_DEVOLUCAO_2020',\n",
    "                                 'QT_VENDA_BRUTO_2018','QT_VENDA_BRUTO_2019','QT_VENDA_BRUTO_2020',\n",
    "                                 'VL_RECEITA_BRUTA_2018','VL_RECEITA_BRUTA_2019','VL_RECEITA_BRUTA_2020',\n",
    "                                 'VL_RECEITA_LIQUIDA_2018','VL_RECEITA_LIQUIDA_2019','VL_RECEITA_LIQUIDA_2020'], axis=1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colunas\n",
    "df_cluster['QT_DEVOLUCAO'] = df_cluster['QT_DEVOLUCAO_2018'] + df_cluster['QT_DEVOLUCAO_2019'] + df_cluster['QT_DEVOLUCAO_2020']\n",
    "df_cluster['QT_VENDA_BRUTO'] = df_cluster['QT_VENDA_BRUTO_2018'] + df_cluster['QT_VENDA_BRUTO_2019'] + df_cluster['QT_VENDA_BRUTO_2020']\n",
    "df_cluster['VL_RECEITA_BRUTA'] = df_cluster['VL_RECEITA_BRUTA_2018'] + df_cluster['VL_RECEITA_BRUTA_2019'] + df_cluster['VL_RECEITA_BRUTA_2020']\n",
    "df_cluster['VL_RECEITA_LIQUIDA'] = df_cluster['VL_RECEITA_LIQUIDA_2018'] + df_cluster['VL_RECEITA_LIQUIDA_2019'] + df_cluster['VL_RECEITA_LIQUIDA_2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster['VAR_RECEITA'] = (df_cluster['VL_RECEITA_LIQUIDA'] - df_cluster['VL_RECEITA_BRUTA']) / df_cluster['VL_RECEITA_BRUTA']\n",
    "df_cluster['PROP_DEVOLUCAO'] = df_cluster['QT_DEVOLUCAO']/df_cluster['QT_VENDA_BRUTO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = df_cluster.drop(['QT_DEVOLUCAO_2018','QT_DEVOLUCAO_2019','QT_DEVOLUCAO_2020',\n",
    "                              'QT_VENDA_BRUTO_2018','QT_VENDA_BRUTO_2019','QT_VENDA_BRUTO_2020',\n",
    "                              'VL_RECEITA_BRUTA_2018','VL_RECEITA_BRUTA_2019','VL_RECEITA_BRUTA_2020',\n",
    "                              'QT_DEVOLUCAO','VL_RECEITA_BRUTA'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019/2018\n",
    "df_cluster['VAR_1'] = (df_cluster['VL_RECEITA_LIQUIDA_2019'] -  df_cluster['VL_RECEITA_LIQUIDA_2018'])/df_cluster['VL_RECEITA_LIQUIDA_2018']\n",
    "\n",
    "# 2020/2019\n",
    "df_cluster['VAR_2'] = (df_cluster['VL_RECEITA_LIQUIDA_2020'] -  df_cluster['VL_RECEITA_LIQUIDA_2019'])/df_cluster['VL_RECEITA_LIQUIDA_2019']\n",
    "\n",
    "df_cluster.replace([np.inf,-np.inf],1,inplace=True)\n",
    "df_cluster = df_cluster.fillna(0)\n",
    "\n",
    "#média de variações\n",
    "df_cluster['MEDIA_VAR'] = (df_cluster['VAR_1'] + df_cluster['VAR_2'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preço\n",
    "df_preco = base.groupby(['COD_MATERIAL'], as_index=False)['VL_PRECO'].mean()\n",
    "df_preco  = df_preco.set_axis(['COD_MATERIAL','MEDIA_PRECO'], axis=1, inplace=False)\n",
    "df_preco  = df_preco.sort_values(by=['MEDIA_PRECO'],ascending=False)\n",
    "df_preco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = pd.merge(df_cluster,df_preco,on= ['COD_MATERIAL'], how='left' )\n",
    "df_cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantidade de venda por flag de evento\n",
    "df_qtd = base.groupby(['COD_MATERIAL','FLG_DATA'], as_index=False)['QT_VENDA_BRUTO'].sum()\n",
    "df_qtd  = df_qtd.set_axis(['COD_MATERIAL','FLG_DATA','QT_VENDA_BRUTO'], axis=1, inplace=False)\n",
    "df_qtd  = df_qtd.sort_values(by=['QT_VENDA_BRUTO'],ascending=False)\n",
    "\n",
    "df_qtd = pd.pivot_table(df_qtd , values = ['QT_VENDA_BRUTO'],index = ['COD_MATERIAL'],\n",
    "            columns = ['FLG_DATA'], aggfunc = np.sum, fill_value=0)\n",
    "    \n",
    "df_qtd.reset_index(inplace=True)  \n",
    "df_qtd = df_qtd.set_axis(['COD_MATERIAL','QT_VENDA_BRUTO_0','QT_VENDA_BRUTO_1'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = pd.merge(df_cluster,df_qtd,on= ['COD_MATERIAL'], how='left' )\n",
    "df_cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recencia\n",
    "aux = ('202008', '202009', '202010','202011','202012','202013','202014','202015','202016','202017')\n",
    "df_recencia = base[base.COD_CICLO.isin(aux)]\n",
    "df_recencia\n",
    "\n",
    "df_recencia_2 = df_recencia.groupby('COD_MATERIAL', as_index=False)['COD_CICLO'].nunique()\n",
    "\n",
    "df_recencia_2 = df_recencia_2.set_axis(['COD_MATERIAL','RECENCIA'],axis=1, inplace= False)\n",
    "df_recencia_2\n",
    "\n",
    "print(df_recencia_2.RECENCIA.max())\n",
    "print(df_recencia_2.RECENCIA.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#frequencia\n",
    "df_frequencia =  base[base['COD_CICLO'] != '202101']\n",
    "\n",
    "df_frequencia_2 = df_frequencia.groupby('COD_MATERIAL', as_index=False)['COD_CICLO'].nunique()\n",
    "\n",
    "df_frequencia_2 = df_frequencia_2.set_axis(['COD_MATERIAL','FREQUENCIA'],axis=1, inplace= False)\n",
    "\n",
    "print(df_frequencia_2.FREQUENCIA.max())\n",
    "print(df_frequencia_2.FREQUENCIA.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valor\n",
    "df_valor =  base[base['COD_CICLO'] != '202101']\n",
    "\n",
    "df_valor_2 = df_valor.groupby(['COD_MATERIAL']).agg(\n",
    "{'VL_RECEITA_LIQUIDA': 'sum',\n",
    " 'COD_CICLO': 'nunique'}\n",
    ")\n",
    "\n",
    "df_valor_2['TICKET_CICLO'] = df_valor_2['VL_RECEITA_LIQUIDA']/df_valor_2['COD_CICLO']\n",
    "df_valor_2 = df_valor_2.drop(['COD_CICLO','VL_RECEITA_LIQUIDA'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = pd.merge(df_cluster,df_recencia_2,on= ['COD_MATERIAL'], how='left' )\n",
    "df_cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = pd.merge(df_cluster,df_frequencia_2,on= ['COD_MATERIAL'], how='left' )\n",
    "df_cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = pd.merge(df_cluster,df_valor_2,on= ['COD_MATERIAL'], how='left' )\n",
    "df_cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = df_cluster.drop(['VL_RECEITA_LIQUIDA_2018','VL_RECEITA_LIQUIDA_2019','VL_RECEITA_LIQUIDA_2020','VAR_1','VAR_2'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = df_cluster.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 Padronizando o dataframe e gerando o modelo Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronizando as variáveis\n",
    "escala=StandardScaler()\n",
    "df_cluster_normal = pd.DataFrame(escala.fit_transform(df_cluster.iloc[:,1:12]),columns=['QT_VENDA_BRUTO','VL_RECEITA_LIQUIDA','VAR_RECEITA','PROP_DEVOLUCAO','MEDIA_VAR','MEDIA_PRECO','QT_VENDA_BRUTO_0','QT_VENDA_BRUTO_1','RECENCIA','FREQUENCIA','TICKET_CICLO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo das iterações do k-means (Cotovelo)\n",
    "# O número de iterações é subjetivo, utilizou-se 10, pois com esse número é possível avaliar\n",
    "# o ponto de flexão da curva, mas se desejar é possível testar com valor maior ou menor\n",
    "\n",
    "wcss = {}\n",
    "for k in range(1, 15):\n",
    "  print(k)\n",
    "  kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=200, random_state=3)\n",
    "  kmeans.fit(df_cluster_normal)\n",
    "  wcss[k] = kmeans.inertia_\n",
    "\n",
    "# No código abaixo será gerado o gráfico que permite aplicação do método do \"cotovelo\"\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=1,\n",
    "    subplot_titles=['Método do Cotovelo'],\n",
    "    shared_xaxes=True,\n",
    "    shared_yaxes=False)\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(wcss.keys()),\n",
    "        y=list(wcss.values()),\n",
    "        mode='lines+markers',\n",
    "        textposition='top center',\n",
    "        showlegend=False),\n",
    "    row=1, \n",
    "    col=1)\n",
    "\n",
    "fig.update_xaxes(visible=True, title='N° de clusters',row=1, col=1)\n",
    "fig.update_yaxes(visible=True, title='Soma dos quadrados totais dos clusters',row=1, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "  title='Definição do Nº Ideal de Clusters',\n",
    "  showlegend=False,\n",
    "  xaxis_showticklabels=True,\n",
    "  height=400,\n",
    "  width=800,\n",
    "  xaxis = dict(\n",
    "    tickmode = 'linear',\n",
    "    tick0 = 0,\n",
    "    dtick = 1))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#silhouette_score\n",
    "\n",
    "maior_score = 0\n",
    "i_otimo = 2\n",
    "\n",
    "for i in range(2, 15):\n",
    "    clusterer = KMeans(n_clusters=i)\n",
    "    preds = clusterer.fit_predict(df_cluster_normal)\n",
    "    score = silhouette_score(df_cluster_normal, preds)\n",
    "\n",
    "    if score > maior_score:\n",
    "        maior_score = score\n",
    "        i_otimo = i\n",
    "    print('Silhouette score para ' + str(i) + ' clusters: ' +str(score))\n",
    "    \n",
    "print('Maior score: ' + str(maior_score))\n",
    "print('Número ideal de clusters: ' + str(i_otimo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição do DF a ser Clusterizado\n",
    "# tamanho de 5 clusters\n",
    "# Clusterização\n",
    "clus = KMeans(n_clusters = i_otimo, init='k-means++', max_iter=300,random_state=3)\n",
    "clus.fit(df_cluster_normal)\n",
    "\n",
    "# Ajustando as colunas\n",
    "df_cluster_normal.loc[:, 'CLUSTER'] = clus.labels_\n",
    "df_cluster_normal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster\n",
    "# Dataset não padronizado\n",
    "df_cluster.loc[:, 'CLUSTER'] = clus.labels_\n",
    "df_cluster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3 Distribuição do cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mat = df_cluster.groupby(['COD_MATERIAL','CLUSTER'],as_index=False)['VL_RECEITA_LIQUIDA'].sum()\n",
    "df_mat = df_mat.set_axis(['COD_MATERIAL','CLUSTER','VL_RECEITA_LIQUIDA'], axis=1, inplace=False)\n",
    "df_mat = df_mat.drop(['VL_RECEITA_LIQUIDA'],axis=1)\n",
    "df_mat \n",
    "\n",
    "base2 = pd.merge(base,df_mat,on= ['COD_MATERIAL'], how='left')\n",
    "base2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volumetria  - quantidade de materiais por cluster\n",
    "df_cluster['CLUSTER'].value_counts().plot(kind=\"bar\")\n",
    "plt.title('Qtd de produtos por Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Qtd de produtos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição de VL_RECEITA_LIQUIDA por CLUSTER\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# plot a bar chart\n",
    "sns.barplot(\n",
    "    y=\"VL_RECEITA_LIQUIDA\", \n",
    "    x=\"CLUSTER\", \n",
    "    data=df_cluster, \n",
    "    estimator=sum, \n",
    "    ci=None );\n",
    "\n",
    "plt.title('Valor de receita líquida por Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Valor de venda líquida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição de VL_RECEITA_BRUTA por CLUSTER\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# plot a bar chart\n",
    "sns.barplot(\n",
    "    y=\"VL_RECEITA_BRUTA\", \n",
    "    x=\"CLUSTER\", \n",
    "    data=base2, \n",
    "    estimator=sum, \n",
    "    ci=None );\n",
    "\n",
    "plt.title('Valor de receita bruta por Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Valor de venda bruta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição de QT_VENDA_BRUTO por CLUSTER\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# plot a bar chart\n",
    "sns.barplot(\n",
    "    y=\"QT_VENDA_BRUTO\", \n",
    "    x=\"CLUSTER\", \n",
    "    data=df_cluster, \n",
    "    estimator=sum, \n",
    "    ci=None );\n",
    "\n",
    "plt.title('Quantidade de Venda Bruta por Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Quantidade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição de QT_VENDA_BRUTO por CLUSTER\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# plot a bar chart\n",
    "sns.barplot(\n",
    "    y=\"QT_DEVOLUCAO\", \n",
    "    x=\"CLUSTER\", \n",
    "    data=base2, \n",
    "    estimator=sum, \n",
    "    ci=None );\n",
    "\n",
    "plt.title('Quantidade de devoluções por Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Quantidade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Média de recência por CLUSTER\n",
    "cluster_recencia = df_cluster.groupby('CLUSTER', as_index=False)['RECENCIA'].mean()\n",
    "cluster_recencia = cluster_recencia .set_axis(['CLUSTER', 'MEDIA_RECENCIA'], axis=1, inplace=False)\n",
    "cluster_recencia = cluster_recencia .sort_values(by=['MEDIA_RECENCIA'],ascending=False)\n",
    "\n",
    "plt.bar(cluster_recencia ['CLUSTER'] ,cluster_recencia ['MEDIA_RECENCIA'])\n",
    "plt.title('Média de recência por Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Média de recencia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Média de frequência por CLUSTER\n",
    "cluster_frequencia = df_cluster.groupby('CLUSTER', as_index=False)['FREQUENCIA'].mean()\n",
    "cluster_frequencia = cluster_frequencia.set_axis(['CLUSTER', 'MEDIA_FREQUENCIA'], axis=1, inplace=False)\n",
    "cluster_frequencia = cluster_frequencia.sort_values(by=['MEDIA_FREQUENCIA'],ascending=False)\n",
    "\n",
    "plt.bar(cluster_frequencia ['CLUSTER'] ,cluster_frequencia['MEDIA_FREQUENCIA'])\n",
    "plt.title('Média de frequência por Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Média de frequência')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Média de ticket_ciclo\n",
    "cluster_media_ciclo = df_cluster.groupby('CLUSTER', as_index=False)['TICKET_CICLO'].mean()\n",
    "cluster_media_ciclo = cluster_media_ciclo.set_axis(['CLUSTER', 'MEDIA_TICKET_CICLO'], axis=1, inplace=False)\n",
    "cluster_media_ciclo = cluster_media_ciclo.sort_values(by=['MEDIA_TICKET_CICLO'],ascending=False)\n",
    "\n",
    "plt.bar(cluster_media_ciclo['CLUSTER'] ,cluster_media_ciclo['MEDIA_TICKET_CICLO'])\n",
    "plt.title('Média de ticket ciclo por Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Média de frequência')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlação entre as variáveis do cluster\n",
    "sns.heatmap(data = df_cluster.corr(),cmap='coolwarm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlação entre quantidade de campanhas e valor de receita líquida - Cluster 3\n",
    "corr_campanha_cluster3 = base2[base2['CLUSTER'] == 1].groupby(['COD_CICLO',],as_index=False).agg(\n",
    "    {'FLG_CAMPANHA_MKT_A':'sum',\n",
    "     'FLG_CAMPANHA_MKT_B':'sum',\n",
    "     'FLG_CAMPANHA_MKT_C':'sum',\n",
    "     'FLG_CAMPANHA_MKT_D':'sum',\n",
    "     'VL_RECEITA_LIQUIDA':'sum',\n",
    "    })\n",
    "\n",
    "corr_campanha_cluster3\n",
    "\n",
    "plt.title(\"Quantidade de campanhas e valor de receita líquida - Cluster 3\")\n",
    "sns.heatmap(corr_campanha_cluster3.corr(),cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlação entre quantidade de campanhas e vquantidade de venda bruta - Cluster 3\n",
    "corr_campanha_cluster3_qtd = base2[base2['CLUSTER'] == 1].groupby(['COD_CICLO',],as_index=False).agg(\n",
    "    {'FLG_CAMPANHA_MKT_A':'sum',\n",
    "     'FLG_CAMPANHA_MKT_B':'sum',\n",
    "     'FLG_CAMPANHA_MKT_C':'sum',\n",
    "     'FLG_CAMPANHA_MKT_D':'sum',\n",
    "     'QT_VENDA_BRUTO':'sum',\n",
    "    })\n",
    "\n",
    "corr_campanha_cluster3_qtd\n",
    "\n",
    "plt.title(\"Quantidade de campanhas e quantidade de venda bruta - Cluster 3\")\n",
    "sns.heatmap(corr_campanha_cluster3_qtd.corr(),cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exportar resultado\n",
    "df_cluster.to_excel('df_cluster_novo.xlsx')\n",
    "base2.to_excel('base2_novo.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.4 Resultados dos cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 1 - Modelo campeão\n",
    "\n",
    "Utilizei o modelo K-means para clusterizar os materiais em grupos com característica comuns, e através desse modelo, melhorar os resultado de vendas da empresa. Obtive como grupo mais relevante o cluster 1 pois representa 50,38% da receita líquida com apenas 58 materiais, o que representa a oportunidade de desenvolver uma estratégia de venda com baixo esforço de implementação e alto impacto financeiro.\n",
    "\n",
    "O cluster 1 é grupo de materiais com valor agregado alto (Média de preço: 839,95 reais) e uma boa recência em ciclos (Média de recência: 9,81 de 10), frequência em ciclos (Média de frequência: 44 de 52) e ticket-médio por ciclo (Média de ticket por ciclo: ~ 23 Milhões de reais).\n",
    "\n",
    "Para alavancar as vendas é necessário focar no canal anon_s7(31,14% da venda líquida total), na categoria anon_S12 (43,30% da venda líquida total), e região anon_S1 (28,60% da venda líquida total). Além disso, o cluster possui uma quantidade pequena de 19 marcas. \n",
    "\n",
    "Sobre as campanhas de venda, a parcela maior de participação (6,61% da quantidade de campanhas) corresponde as campanhas B (5,22%) e D (1,39%). Na matriz de correlação da quantidade de vendas e quantidade de campanhas por flag, o cluster 1 teve uma correlação positiva alta de 0.6 com a campanha B e uma correlação positiva fraca de 0.2 com a campanha D. Sendo B e D as campanhas que obtiveram maior retorno financeiro.\n",
    "\n",
    "Estratégias de venda para o cluster 1:\n",
    "\n",
    "- Desenvolver campanhas de marketing que enfatizem o valor dos materiais para o cliente, independente do preço do material. É um cluster com materiais de valor agregado alto que precisa ser alinhado a um público-alvo específico, os que não se preocupam com preço, mas esperam valor (qualidade, diferenciação e outros) no material. \n",
    "\n",
    "- Garantir uma boa experiência de compra. Investir em um ambiente acolhedor, atendimento atencioso, transparência sobre as características dos produtos e flexibilidade de opções.\n",
    "\n",
    "- É necessário direcionar os produtos para canais e regiões específicas,fazer uma boa análise dos dados garante um bom escoamento do produto. \n",
    "\n",
    "- Como o sucesso desse cluster depende principalmente do match com o público-alvo, investir em estratégias de marketing inbound\n",
    "para conseguir novos cliente. Segundo SIQUEIRA,\"No Inbound Marketing, é o cliente que procura pela empresa e não o contrário.\n",
    "Ou seja, são realizadas ações com o intuito de atrair o potencial cliente para seu blog ou site e, a partir dessa atração, é feito todo um trabalho de relacionamento com essa pessoa. Esse relacionamento é desempenhado por meio de conteúdo personalizado e autoral\".\n",
    "\n",
    "- Outra estratégia para obter novos clientes é a demonstração do produto, nesse momento o cliente conhecerá o produto e despertará o desejo de compra.\n",
    "\n",
    "- Para produtos com valor alto é uma estratégia investir em um pós-venda com serviços acima da média, o que gera valor aos olhos do cliente, atende a expectativa de diferenciação e retém o público-alvo.\n",
    "\n",
    "- Para complementar a estratégia de vendas foi desenvolvido um modelo de classificação para identificar os materiais do cluster 1 e 2 modelos de regressão para prever a quantidade de venda bruta e valor de receita líquida do cluster 1.\n",
    "\n",
    "\n",
    "Comentários sobre o cluster 0\n",
    "\n",
    "O cluster 0 representa do 49,62% do total de vendas líquidas e 64,83% da quantidade total de vendas, no entanto, esse cluster possui 2172 materiais únicos, essa quantidade quando comparada a quantidade de materiais do cluster 0 (53 materiais) evidencia o alto esforço para desenvolver uma estratégia de alavancagem de venda nesse cluster.\n",
    "\n",
    "Fontes:\n",
    "\n",
    "SIQUEIRA, André.2022.Tudo sobre Inbound Marketing. Disponível em:<https://resultadosdigitais.com.br/marketing/o-que-e-inbound-marketing/>. Acesso em: 05/12/2022.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.1 Preparação dos dados - Modelo 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_classe = df_cluster[['COD_MATERIAL','CLUSTER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = pd.merge(base[base.COD_CICLO !='202101'] ,df_cluster_classe,on= ['COD_MATERIAL'], how='left' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.CLUSTER.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = df_class.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena as colunas criadas ao dataframe\n",
    "df_class_encoding = pd.concat([df_class.drop(\"COD_CANAL\", axis=1), pd.get_dummies(df_class.COD_CANAL,prefix='CANAL', prefix_sep='_')], axis=1)\n",
    "df_class_encoding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena as colunas criadas ao dataframe\n",
    "df_class_encoding = pd.concat([df_class_encoding.drop(\"DES_CATEGORIA_MATERIAL\", axis=1), pd.get_dummies(df_class.DES_CATEGORIA_MATERIAL,prefix='CATEGORIA', prefix_sep='_')], axis=1)\n",
    "df_class_encoding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena as colunas criadas ao dataframe\n",
    "df_class_encoding = pd.concat([df_class_encoding.drop(\"DES_MARCA_MATERIAL\", axis=1), pd.get_dummies(df_class.DES_MARCA_MATERIAL,prefix='MARCA', prefix_sep='_')], axis=1)\n",
    "df_class_encoding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena as colunas criadas ao dataframe\n",
    "df_class_encoding = pd.concat([df_class_encoding.drop(\"COD_REGIAO\", axis=1), pd.get_dummies(df_class.COD_REGIAO,prefix='REGIAO', prefix_sep='_')], axis=1)\n",
    "df_class_encoding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding['PROP_DEVOLUCAO'] = df_class_encoding['QT_DEVOLUCAO']/df_class_encoding['QT_VENDA_BRUTO']\n",
    "df_class_encoding['VAR_RECEITA'] = (df_class_encoding['VL_RECEITA_LIQUIDA'] - df_class_encoding['VL_RECEITA_BRUTA'])/df_class_encoding['VL_RECEITA_BRUTA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding = df_class_encoding.drop(['COD_CICLO','QT_DEVOLUCAO','VL_RECEITA_BRUTA','COD_MATERIAL'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_class_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.2 Classificação - Modelo 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding['CLUSTER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split\n",
    "X, y = df_class_encoding.drop('CLUSTER',axis=1), df_class_encoding.CLUSTER\n",
    "\n",
    "print(\"X\", X.shape)\n",
    "print(\"y\", y.shape)\n",
    "\n",
    "# Usar train_test_split para criar o conjunto de teste\n",
    "X_training, X_test, y_training, y_test = train_test_split(X, y, random_state=seed, test_size=0.25, stratify=y)\n",
    "\n",
    "# Como saída, temos a porção de treino e teste para as variáveis X e Y\n",
    "\n",
    "print(\"Test set X\", X_test.shape)\n",
    "print(\"Test set y\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier - MODELO 1\n",
    "\n",
    "# Gerar um objeto árvore usando uma semente (seed) para resultados reproduzíveis\n",
    "modelo_1 = RandomForestClassifier(criterion = 'entropy', random_state=seed)\n",
    "\n",
    "# Fitar, ou treinar, o modelo usando o dataset de treino\n",
    "modelo_1.fit(X_training, y_training)\n",
    "\n",
    "# Prever todos os resultados no dataset de validação\n",
    "y_pred_1 = modelo_1.predict(X_test)\n",
    "\n",
    "# Calcular e printar métricas\n",
    "\n",
    "# A função score da nossa árvore calcula a acurácia, tendo como entradas as variáveis X e y e, por trás, essa função gerará o y previsto e irá comparar com o y real (variável y_train, por exemplo)\n",
    "print(\"Acurácia no conjunto de treino: {:.3f}\".format(modelo_1.score(X_training, y_training)))\n",
    "print(\"Acurácia no conjunto de teste: {:.3f}\".format(modelo_1.score(X_test, y_test)))\n",
    "\n",
    "# O classification report traz diversas métricas interessantes, en formato de tabela, de forma simples\n",
    "print(classification_report(y_test, y_pred_1))\n",
    "\n",
    "# A matriz de confusão mostra de forma fácil os dados\n",
    "# Verdadeiros Positivos | Falsos Positivos\n",
    "# Falsos Negativos | Verdadeiros Negativos\n",
    "print(confusion_matrix(y_test, y_pred_1))\n",
    "print(\"Área sob a curva ROC: {:.3f}\".format(roc_auc_score(y_test, y_pred_1)))\n",
    "\n",
    "# Plotar importância das features\n",
    "# Avalia quão importante é cada variável para as decisões que a árvore fornece\n",
    "\n",
    "feature_scores_1 = pd.Series(modelo_1.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(feature_scores_1)\n",
    "\n",
    "# Creating a seaborn bar plot\n",
    "sns.barplot(x=feature_scores_1, y=feature_scores_1.index)\n",
    "\n",
    "# Add labels to the graph\n",
    "plt.xlabel('Importância das variáveis')\n",
    "plt.ylabel('Variáveis')\n",
    "\n",
    "# Add title to the graph\n",
    "plt.title(\"Importância das variáveis\")\n",
    "\n",
    "# Visualize the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.3 Preparação dos dados - Modelo 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding_2 = df_class\n",
    "df_class_encoding_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding_2['PROP_DEVOLUCAO'] = df_class_encoding_2['QT_DEVOLUCAO']/df_class_encoding_2['QT_VENDA_BRUTO']\n",
    "df_class_encoding_2['VAR_RECEITA'] = (df_class_encoding_2['VL_RECEITA_LIQUIDA'] - df_class_encoding_2['VL_RECEITA_BRUTA'])/df_class_encoding_2['VL_RECEITA_BRUTA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding_2 = df_class_encoding_2.drop(['COD_CICLO','COD_MATERIAL','QT_DEVOLUCAO','VL_RECEITA_BRUTA','ANO'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding_2.CLUSTER.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena as colunas criadas ao dataframe\n",
    "df_class_encoding_2 = pd.concat([df_class_encoding_2.drop(\"COD_CANAL\", axis=1), pd.get_dummies(df_class_encoding_2.COD_CANAL,prefix='CANAL', prefix_sep='_')], axis=1)\n",
    "df_class_encoding_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica o One Hot Encoding na coluna agrupada e concatena o resultado ao dataframe df_class_encoding_2, descartando a coluna original\n",
    "df_class_encoding_2 = pd.concat([df_class_encoding_2.drop(\"COD_REGIAO\", axis=1), pd.get_dummies(df_class_encoding_2.COD_REGIAO,prefix='REGIAO', prefix_sep='_')], axis=1)\n",
    "df_class_encoding_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula o valor médio de VL_RECEITA_LIQUIDA por categoria de DES_CATEGORIA_MATERIAL\n",
    "df_class_encoding_2.VL_RECEITA_LIQUIDA.groupby(df_class_encoding_2['DES_CATEGORIA_MATERIAL']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupamento das categorias de DES_CATEGORIA_MATERIAL\n",
    "def get_periods_of_category(arg1):\n",
    "    '''Retorna os periodos de sol a partir da categoria Sun'''\n",
    "    if arg1 == 'anon_S11' or arg1 == 'anon_S18' or arg1 =='anon_S30' or arg1 =='anon_S5':\n",
    "        return '1'\n",
    "    elif arg1 == 'anon_S2':\n",
    "        return '2'\n",
    "    elif arg1 == 'anon_S12':\n",
    "        return '3'\n",
    "    else:\n",
    "        return 'outro'\n",
    "\n",
    "\n",
    "df_class_encoding_2['CATEGORIA_PERIODO'] = df_class_encoding_2.DES_CATEGORIA_MATERIAL.apply(get_periods_of_category)\n",
    "df_class_encoding_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica o One Hot Encoding na coluna agrupada e concatena o resultado ao dataframe [df_class_encoding_2, descartando a coluna original\n",
    "df_class_encoding_2 = pd.concat([df_class_encoding_2.drop(\"CATEGORIA_PERIODO\", axis=1), pd.get_dummies(df_class_encoding_2['CATEGORIA_PERIODO'],prefix='CATEGORIA', prefix_sep='_' )], axis=1)\n",
    "df_class_encoding_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula o valor médio de VL_RECEITA_LIQUIDA por categoria de DES_MARCA_MATERIAL\n",
    "df_categoria_marca = pd.DataFrame(df_class_encoding_2.VL_RECEITA_LIQUIDA.groupby(df_class_encoding_2['DES_MARCA_MATERIAL']).mean())\n",
    "df_categoria_marca.reset_index(inplace=True)  \n",
    "df_categoria_marca = df_categoria_marca.set_axis(['DES_MARCA_MATERIAL','MEDIA_MARCA'],axis=1, inplace= False)\n",
    "df_categoria_marca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding_2 = pd.merge(df_class_encoding_2, df_categoria_marca, on= ['DES_MARCA_MATERIAL'], how='left')\n",
    "df_class_encoding_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = df_categoria_marca.MEDIA_MARCA.min()\n",
    "max = df_categoria_marca.MEDIA_MARCA.max()\n",
    "\n",
    "amplitude = max - min\n",
    "n= 5 \n",
    "tamanho = (amplitude/ n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupamento das categorias de DES_CATEGORIA_MATERIAL\n",
    "def obter_intervalo_marca(arg1):\n",
    "    '''Retorna os periodos de sol a partir da categoria Sun'''\n",
    "    min_local = min\n",
    "    max_local = max\n",
    "    amplitude_local = (max_local - min_local)\n",
    "    n_local = 5\n",
    "    tamanho_local = float( amplitude_local/ n_local)\n",
    "    \n",
    "    if arg1 >= 0 and arg1 < tamanho_local:\n",
    "        return '1'\n",
    "    elif arg1 >= tamanho_local and arg1 < tamanho_local*2:\n",
    "        return '2'\n",
    "    elif arg1 >= tamanho_local*2 and arg1 < tamanho_local*3:\n",
    "        return '3'\n",
    "    elif arg1 >= tamanho_local*3 and arg1 < tamanho_local*4:\n",
    "        return '4'\n",
    "    elif arg1 >= tamanho_local*5:\n",
    "        return '5'\n",
    "    else:\n",
    "        return 'outro'\n",
    "\n",
    "\n",
    "df_class_encoding_2['CATEGORIA_MARCA'] = df_class_encoding_2.MEDIA_MARCA.apply(obter_intervalo_marca)\n",
    "df_class_encoding_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding_2['CATEGORIA_MARCA'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica o One Hot Encoding na coluna agrupada e concatena o resultado ao dataframe [df_class_encoding_2, descartando a coluna original\n",
    "df_class_encoding_2 = pd.concat([df_class_encoding_2.drop(\"CATEGORIA_MARCA\", axis=1), pd.get_dummies(df_class_encoding_2['CATEGORIA_MARCA'],prefix='MARCA', prefix_sep='_' )], axis=1)\n",
    "df_class_encoding_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding_2 = df_class_encoding_2.drop(['DES_CATEGORIA_MATERIAL','DES_MARCA_MATERIAL','MEDIA_MARCA'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.4 Classificação - Modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_class_encoding_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz de correlação\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(df_class_encoding_2.corr(),cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding_2.CLUSTER.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split\n",
    "X2, y2 = df_class_encoding_2.drop(['CLUSTER'],axis=1), df_class_encoding_2['CLUSTER']\n",
    "\n",
    "print(\"X\", X2.shape)\n",
    "print(\"y\", y2.shape)\n",
    "\n",
    "# Usar train_test_split para criar o conjunto de teste\n",
    "X2_training, X2_test, y2_training, y2_test = train_test_split(X2, y2, random_state=seed, test_size=0.25, stratify=y)\n",
    "\n",
    "# Como saída, temos a porção de treino e teste para as variáveis X e Y\n",
    "print(\"Test set X\", X2_test.shape)\n",
    "print(\"Test set y\", y2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier - MODELO 2\n",
    "\n",
    "# Gerar um objeto árvore usando uma semente (seed) para resultados reproduzíveis\n",
    "modelo_2 = RandomForestClassifier(criterion = 'entropy',random_state=seed)\n",
    "\n",
    "# Fitar, ou treinar, o modelo usando o dataset de treino\n",
    "modelo_2.fit(X2_training, y2_training)\n",
    "\n",
    "# Usa o modelo para prever o conjunto de teste\n",
    "y_pred_2 = modelo_2.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calcular e printar métricas\n",
    "\n",
    "# A função score da nossa árvore calcula a acurácia, tendo como entradas as variáveis X e y e, por trás, essa função gerará o y previsto e irá comparar com o y real\n",
    "print(\"Acurácia no conjunto de treino: {:.3f}\".format(modelo_2.score(X2_training, y2_training)))\n",
    "print(\"Acurácia no conjunto de teste: {:.3f}\".format(modelo_2.score(X2_test, y2_test)))\n",
    "\n",
    "# O classification report traz diversas métricas interessantes, en formato de tabela, de forma simples\n",
    "print(classification_report(y2_test, y_pred_2))\n",
    "\n",
    "# A matriz de confusão mostra de forma fácil os dados\n",
    "# Verdadeiros Positivos | Falsos Positivos\n",
    "# Falsos Negativos | Verdadeiros Negativos\n",
    "print(confusion_matrix(y2_test, y_pred_2))\n",
    "print(\"Área sob a curva ROC: {:.3f}\".format(roc_auc_score(y2_test, y_pred_2)))\n",
    "\n",
    "# Plotar importância das features\n",
    "# Avalia quão importante é cada variável para as decisões que o modleo fornece\n",
    "\n",
    "feature_scores_2 = pd.Series(modelo_2.feature_importances_, index=X2.columns).sort_values(ascending=False)\n",
    "print(feature_scores_2)\n",
    "\n",
    "# Criando um plot\n",
    "sns.barplot(x=feature_scores_2, y=feature_scores_2.index)\n",
    "\n",
    "# labels\n",
    "plt.xlabel('Importância das variáveis')\n",
    "plt.ylabel('Variáveis')\n",
    "\n",
    "# título\n",
    "plt.title(\"Importância das variáveis\")\n",
    "\n",
    "# visualizar\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.5 Classificação - Modelo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding_2.CLUSTER.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split\n",
    "X3, y3 = df_class_encoding_2.drop(['CLUSTER','REGIAO_anon_S10','VAR_RECEITA','FLG_CAMPANHA_MKT_B','FLG_CAMPANHA_MKT_D','FLG_CAMPANHA_MKT_A','CANAL_anon_S7','CANAL_anon_S0','FLG_CAMPANHA_MKT_C','MARCA_1','MARCA_2','MARCA_5','FLG_CAMPANHA_MKT_E'],axis=1), df_class_encoding_2['CLUSTER']\n",
    "\n",
    "print(\"X3\", X3.shape)\n",
    "print(\"y3\", y3.shape)\n",
    "\n",
    "# Usar train_test_split para criar o conjunto de teste\n",
    "X3_training, X3_test, y3_training, y3_test = train_test_split(X3, y3, random_state=seed, test_size=0.25, stratify=y)\n",
    "\n",
    "# Como saída, temos a porção de treino e teste para as variáveis X e Y\n",
    "print(\"Test set X\", X3_test.shape)\n",
    "print(\"Test set y\", y3_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier com validação cruzada e GridSearch - modelo 3\n",
    "\n",
    "# Definir os possiveis valores para cada hiperparametro para serem explorados\n",
    "params3 = {'max_depth': [2, 3, 4, 5, 6],\n",
    "          'min_samples_split': [2, 3, 4, 5, 6],\n",
    "          'min_samples_leaf': [1, 2, 3]}\n",
    "\n",
    "# Criar objeto com o RandomForestClassifier\n",
    "modelo_3 = RandomForestClassifier(criterion='entropy',random_state=seed)\n",
    "\n",
    "# Criar objeto KFold com StratifiedKFold para validação cruzada\n",
    "skf3 = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "\n",
    "# Criar um objeto de grade de busca com GridSearchCV, a partir dos parâmetros que definimos\n",
    "grid_search_3 = GridSearchCV(modelo_3, param_grid=params3, scoring='roc_auc',\n",
    "                           cv=skf3.split(X3_training, y3_training))\n",
    "\n",
    "# Treinar o modelo com o grid search\n",
    "grid_search_3.fit(X3_training, y3_training)\n",
    "\n",
    "# Printar a melhor combinação de hiperparâmetros\n",
    "print('Melhores hiperparâmetros:')\n",
    "print(grid_search_3.best_params_)\n",
    "\n",
    "#Melhores hiperparâmetros:\n",
    "#{'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera um modelo com as melhores combinações de hiperparâmetros\n",
    "modelo_3 = RandomForestClassifier(criterion='entropy',random_state=seed,\n",
    "                                max_depth=grid_search_3.best_params_['max_depth'],\n",
    "                                min_samples_split=grid_search_3.best_params_['min_samples_split'],\n",
    "                                min_samples_leaf=grid_search_3.best_params_['min_samples_leaf'])\n",
    "\n",
    "# Fita o modelo com o dataset de treino\n",
    "modelo_3.fit(X3_training, y3_training)\n",
    "\n",
    "# Usa o modelo para prever o conjunto de teste\n",
    "y_pred_3 = modelo_3.predict(X3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular e printar métricas\n",
    "\n",
    "# métricas\n",
    "print(\"Acurácia no conjunto de treino: {:.3f}\".format(modelo_3.score(X3_training, y3_training)))\n",
    "print(\"Acurácia no conjunto de teste: {:.3f}\".format(modelo_3.score(X3_test, y3_test)))\n",
    "\n",
    "# O classification report traz diversas métricas interessantes, en formato de tabela, de forma simples\n",
    "print(classification_report(y3_test, y_pred_3))\n",
    "\n",
    "# A matriz de confusão mostra de forma fácil os dados\n",
    "# Verdadeiros Positivos | Falsos Positivos\n",
    "# Falsos Negativos | Verdadeiros Negativos\n",
    "print(confusion_matrix(y3_test, y_pred_3))\n",
    "print(\"Área sob a curva ROC: {:.3f}\".format(roc_auc_score(y3_test, y_pred_3)))\n",
    "\n",
    "# Plotar importância das features\n",
    "# Avalia quão importante é cada variável para as decisões que a árvore fornece\n",
    "\n",
    "feature_scores_3 = pd.Series(modelo_3.feature_importances_, index=X3.columns).sort_values(ascending=False)\n",
    "print(feature_scores_3)\n",
    "\n",
    "# plot\n",
    "sns.barplot(x=feature_scores_3, y=feature_scores_3.index)\n",
    "\n",
    "# labels\n",
    "plt.xlabel('Importância das variáveis')\n",
    "plt.ylabel('Variáveis')\n",
    "\n",
    "# título\n",
    "plt.title(\"Importância das variáveis\")\n",
    "\n",
    "# visualização\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.6 Feature selection com RFE (Eliminação recursiva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split\n",
    "Xrfe, yrfe = df_class_encoding_2.drop(['CLUSTER'],axis=1), df_class_encoding_2['CLUSTER']\n",
    "\n",
    "print(\"Xrfe\", Xrfe.shape)\n",
    "print(\"yrfe\", yrfe.shape)\n",
    "\n",
    "# Usar train_test_split para criar o conjunto de teste\n",
    "Xrfe_training, Xrfe_test, yrfe_training, yrfe_test = train_test_split(Xrfe, yrfe, random_state=seed, test_size=0.25, stratify=y)\n",
    "\n",
    "# Como saída, temos a porção de treino e teste para as variáveis X e Y\n",
    "print(\"Test set Xrfe\", Xrfe_test.shape)\n",
    "print(\"Test set yrfe\", yrfe_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFE\n",
    "estimator = RandomForestClassifier(criterion='entropy',random_state=seed)\n",
    "selector = RFE(estimator,  step=1)\n",
    "selector = selector.fit(Xrfe_training, yrfe_training)\n",
    "print(selector.support_)\n",
    "print(selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_encoding_2.drop(['CLUSTER'],axis=1).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.7 Classificação - Modelo 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split\n",
    "X4, y4 = df_class_encoding_2.drop(['CLUSTER','FLG_CAMPANHA_MKT_B','REGIAO_anon_S10','CANAL_anon_S7','FLG_CAMPANHA_MKT_D','FLG_CAMPANHA_MKT_A','CANAL_anon_S0','FLG_CAMPANHA_MKT_C','MARCA_1','MARCA_2','MARCA_5','FLG_CAMPANHA_MKT_E'],axis=1), df_class_encoding_2.CLUSTER\n",
    "\n",
    "print(\"X4\", X4.shape)\n",
    "print(\"y4\", y4.shape)\n",
    "\n",
    "# Usar train_test_split para criar o conjunto de test\n",
    "X4_training, X4_test, y4_training, y4_test = train_test_split(X4, y4, random_state=seed, test_size=0.25, stratify=y)\n",
    "\n",
    "# Como saída, temos a porção de treino e teste para as variáveis X e Y\n",
    "print(\"Test set X\", X4_test.shape)\n",
    "print(\"Test set y\", y4_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um objeto XGBClassifier\n",
    "modelo_4 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=seed, eval_metric=\"auc\",use_label_encoder=False)\n",
    "\n",
    "# Treinar o modelo usando o conjunto de treino\n",
    "modelo_4.fit(X4_training, y4_training)\n",
    "\n",
    "# Prever todos os resultados no dataset de teste\n",
    "y_pred_4 = modelo_4.predict(X4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular e printar métricas\n",
    "print(\"Acurácia no conjunto de treino: {:.3f}\".format(modelo_4.score(X4_training, y4_training)))\n",
    "print(\"Acurácia no conjunto de teste: {:.3f}\".format(modelo_4.score(X4_test, y4_test)))\n",
    "\n",
    "# O classification report traz diversas métricas interessantes, en formato de tabela, de forma simples\n",
    "print(classification_report(y4_test, y_pred_4.ravel()))\n",
    "\n",
    "# A matriz de confusão mostra de forma fácil os dados\n",
    "# Verdadeiros Positivos | Falsos Positivos\n",
    "# Falsos Negativos | Verdadeiros Negativos\n",
    "print(confusion_matrix(y4_test, y_pred_4.ravel()))\n",
    "print(\"Área sob a curva ROC: {:.3f}\".format(roc_auc_score(y4_test, y_pred_4.ravel())))\n",
    "\n",
    "# Plotar importância das features\n",
    "# Avalia quão importante é cada variável para as decisões que a árvore fornece\n",
    "\n",
    "feature_scores_4 = pd.Series(modelo_4.feature_importances_, index=X4.columns).sort_values(ascending=False)\n",
    "print(feature_scores_4)\n",
    "\n",
    "# plot\n",
    "sns.barplot(x=feature_scores_4, y=feature_scores_4.index)\n",
    "\n",
    "# labels\n",
    "plt.xlabel('Importância das variáveis')\n",
    "plt.ylabel('Variáveis')\n",
    "\n",
    "# título\n",
    "plt.title(\"Importância das variáveis\")\n",
    "\n",
    "# visualização\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.8 Classificação - Modelo 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split\n",
    "X5, y5 = df_class_encoding_2.drop(['CLUSTER','FLG_CAMPANHA_MKT_B','REGIAO_anon_S10','CANAL_anon_S7','FLG_CAMPANHA_MKT_D','FLG_CAMPANHA_MKT_A','CANAL_anon_S0','FLG_CAMPANHA_MKT_C','MARCA_1','MARCA_2','MARCA_5','FLG_CAMPANHA_MKT_E'],axis=1), df_class_encoding_2.CLUSTER\n",
    "\n",
    "print(\"X5\", X5.shape)\n",
    "print(\"y5\", y5.shape)\n",
    "\n",
    "# Usar train_test_split para criar o conjunto de teste\n",
    "X5_training, X5_test, y5_training, y5_test = train_test_split(X5, y5, random_state=seed, test_size=0.25, stratify=y)\n",
    "\n",
    "# Como saída, temos a porção de treino e teste para as variáveis X e Y\n",
    "print(\"Test set X\", X5_test.shape)\n",
    "print(\"Test set y\", y5_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost com Cross Validation e Grid search\n",
    "\n",
    "# Define um conjunto de possíveis valores para os hiperparâmetros\n",
    "params_5 = {'learning_rate': [0.1, 0.2, 0.3],\n",
    "          'alpha': [5, 10, 15],\n",
    "          'colsample_bytree': [0.1, 0.3, 0.5, 0.7, 1.0],\n",
    "          'max_depth': [3, 4, 5]}\n",
    "\n",
    "# Cria o modelo\n",
    "modelo_5 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=seed,\n",
    "                                    eval_metric=\"auc\", n_estimators=10,use_label_encoder=False)\n",
    "\n",
    "# Cria o grid search com validação cruzada estratificada\n",
    "skf_5 = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "grid_search_5 = GridSearchCV(modelo_5, param_grid=params_5, scoring='roc_auc',\n",
    "                           cv=skf_5.split(X5_training, y5_training))\n",
    "\n",
    "# Treina o modelo e printa os melhores hiperparâmetros\n",
    "grid_search_5.fit(X5_training, y5_training)\n",
    "print('\\n Melhores hiperparâmetros:')\n",
    "print(grid_search_5.best_params_)\n",
    "\n",
    "#Melhores hiperparâmetros:\n",
    "#{'alpha': 5, 'colsample_bytree': 0.7, 'learning_rate': 0.3, 'max_depth': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atribui os melhores valores para os hiperparâmetros\n",
    "modelo_5.set_params(learning_rate = grid_search_5.best_params_['learning_rate'],\n",
    "                           alpha = grid_search_5.best_params_['alpha'],\n",
    "                           colsample_bytree = grid_search_5.best_params_['colsample_bytree'],\n",
    "                           max_depth = grid_search_5.best_params_['max_depth'])\n",
    "\n",
    "# Treina o modelo usando os melhores hiperparâmetros\n",
    "modelo_5.fit(X5_training, y5_training)\n",
    "\n",
    "# Prever todos os resultados no dataset de teste\n",
    "y_pred_5 = modelo_5.predict(X5_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular e printar métricas\n",
    "print(\"Acurácia no conjunto de treino: {:.3f}\".format(modelo_5.score(X5_training, y5_training)))\n",
    "print(\"Acurácia no conjunto de teste: {:.3f}\".format(modelo_5.score(X5_test, y5_test)))\n",
    "\n",
    "# O classification report traz diversas métricas interessantes, en formato de tabela, de forma simples\n",
    "print(classification_report(y5_test, y_pred_5))\n",
    "\n",
    "# A matriz de confusão mostra de forma fácil os dados\n",
    "# Verdadeiros Positivos | Falsos Positivos\n",
    "# Falsos Negativos | Verdadeiros Negativos\n",
    "print(confusion_matrix(y5_test, y_pred_5))\n",
    "print(\"Área sob a curva ROC: {:.3f}\".format(roc_auc_score(y5_test, y_pred_5)))\n",
    "\n",
    "# Plotar importância das features\n",
    "# Avalia quão importante é cada variável para as decisões que o modelo fornece\n",
    "\n",
    "feature_scores_5 = pd.Series(modelo_5.feature_importances_, index=X5.columns).sort_values(ascending=False)\n",
    "print(feature_scores_5)\n",
    "\n",
    "#plot\n",
    "sns.barplot(x=feature_scores_5, y=feature_scores_5.index)\n",
    "\n",
    "#labels\n",
    "plt.xlabel('Importância das variáveis')\n",
    "plt.ylabel('Variáveis')\n",
    "\n",
    "# título\n",
    "plt.title(\"Importância das variáveis\")\n",
    "\n",
    "# visualização\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.9 Comparação entre os modelos de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Modelo 1 - Acurácia no conjunto de teste: {:.3f}\".format(modelo_1.score(X_test, y_test)))\n",
    "print(\"Modelo 2 - Acurácia no conjunto de teste: {:.3f}\".format(modelo_2.score(X2_test, y2_test)))\n",
    "print(\"Modelo 3 - Acurácia no conjunto de teste: {:.3f}\".format(modelo_3.score(X3_test, y3_test)))\n",
    "print(\"Modelo 4 - Acurácia no conjunto de teste: {:.3f}\".format(modelo_4.score(X4_test, y4_test)))\n",
    "print(\"Modelo 5 - Acurácia no conjunto de teste: {:.3f}\".format(modelo_5.score(X5_test, y5_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Modelo 1\",classification_report(y_test, y_pred_1))\n",
    "print(\"Modelo 2\",classification_report(y2_test, y_pred_2))\n",
    "print(\"Modelo 3\",classification_report(y3_test, y_pred_3))\n",
    "print(\"Modelo 4\",classification_report(y4_test, y_pred_4))\n",
    "print(\"Modelo 5\",classification_report(y5_test, y_pred_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.10 Resultados da classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o resultado do cluster foi possível verificar que o grupo mais relevante para alavancagem de vendas é cluster 1, sendo assim iniciou-se uma tarefa de aprendizagem supervisonada para classificar os produtos em pertencentes ao cluster 1 (1)  e não pertencente ao cluster 1 (0). Esse modelo é importante para classificar novos materiais de acordo com o desempenho das variáveis históricas. Além disso, a classificação desses materiais traz a vantagem do conhecimento prévio do comportamento do material,ou seja, quais canais,regiões, marcas, categorias, campanhas e outras variáveis com as quais o material performa melhor em venda.\n",
    "\n",
    "O modelo escolhido foi o modelo 4. O modelo 4 (XGBClassifier) foi treinado com as variáveis selecionadas pelo método RFE,por isso, é um modelo menos complexo com 11 variáveis. Apresenta a segunda maior acuracidade (0.968) e o segundo maior recall (0.67). \n",
    "\n",
    "Apesar do modelo 1 apresentar maior acurácia e recall que o modelo 4, seu conjunto de dados dificulta a interpretação dos resultados, visto que é um modelo com mais de 100 variáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Previsão da quantidade de venda bruta - Regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.1 Preparação da base de dados - Modelos 6, 7 e 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao = base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtrar somente o cluster 1\n",
    "aux_mat = df_cluster[df_cluster['CLUSTER'] == 1]\n",
    "aux_mat =  aux_mat['COD_MATERIAL'].unique()\n",
    "print(len(aux_mat))\n",
    "\n",
    "base_previsao_2 = base_previsao[base_previsao['COD_MATERIAL'].isin(aux_mat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_campanha(arg1):\n",
    "    return arg1[-2:]\n",
    "\n",
    "base_previsao_2['N_CAMPANHA'] = base_previsao_2.COD_CICLO.apply(extrair_campanha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_2['N_CAMPANHA'] = base_previsao_2['N_CAMPANHA'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_2.N_CAMPANHA.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COD_MATERIAL\n",
    "df_material_qtd = base_previsao_2.groupby(['COD_MATERIAL','COD_CICLO'], as_index=False)['QT_VENDA_BRUTO'].mean()\n",
    "df_material_qtd  = df_material_qtd.set_axis(['COD_MATERIAL','COD_CICLO','MATERIAL_MEDIA_QTD'], axis=1, inplace=False)\n",
    "df_material_qtd  = df_material_qtd.sort_values(by=['MATERIAL_MEDIA_QTD'],ascending=False)\n",
    "df_material_qtd\n",
    "\n",
    "base_previsao_2 = pd.merge(base_previsao_2,df_material_qtd,on= ['COD_MATERIAL','COD_CICLO'], how='left' )\n",
    "base_previsao_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COD_CANAL\n",
    "df_canal_qtd = base_previsao_2.groupby(['COD_CANAL','COD_CICLO'], as_index=False)['QT_VENDA_BRUTO'].mean()\n",
    "df_canal_qtd  = df_canal_qtd.set_axis(['COD_CANAL','COD_CICLO','CANAL_MEDIA_QTD'], axis=1, inplace=False)\n",
    "df_canal_qtd  = df_canal_qtd.sort_values(by=['CANAL_MEDIA_QTD'],ascending=False)\n",
    "df_canal_qtd\n",
    "\n",
    "base_previsao_2 = pd.merge(base_previsao_2,df_canal_qtd,on= ['COD_CANAL','COD_CICLO'], how='left' )\n",
    "base_previsao_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'DES_CATEGORIA_MATERIAL'\n",
    "df_categoria_qtd = base_previsao_2.groupby(['DES_CATEGORIA_MATERIAL','COD_CICLO'], as_index=False)['QT_VENDA_BRUTO'].mean()\n",
    "df_categoria_qtd  = df_categoria_qtd.set_axis(['DES_CATEGORIA_MATERIAL','COD_CICLO','CATEGORIA_MEDIA_QTD'], axis=1, inplace=False)\n",
    "df_categoria_qtd  = df_categoria_qtd.sort_values(by=['CATEGORIA_MEDIA_QTD'],ascending=False)\n",
    "df_categoria_qtd\n",
    "\n",
    "base_previsao_2 = pd.merge(base_previsao_2,df_categoria_qtd,on= ['DES_CATEGORIA_MATERIAL','COD_CICLO'], how='left' )\n",
    "base_previsao_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'DES_MARCA_MATERIAL'\n",
    "df_marca_qtd = base_previsao_2.groupby(['DES_MARCA_MATERIAL','COD_CICLO'], as_index=False)['QT_VENDA_BRUTO'].mean()\n",
    "df_marca_qtd= df_marca_qtd.set_axis(['DES_MARCA_MATERIAL','COD_CICLO','MARCA_MEDIA_QTD'], axis=1, inplace=False)\n",
    "df_marca_qtd = df_marca_qtd.sort_values(by=['MARCA_MEDIA_QTD'],ascending=False)\n",
    "df_marca_qtd\n",
    "\n",
    "base_previsao_2 = pd.merge(base_previsao_2,df_marca_qtd,on= ['DES_MARCA_MATERIAL','COD_CICLO'], how='left' )\n",
    "base_previsao_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COD_REGIAO\n",
    "df_regiao_qtd = base_previsao_2.groupby(['COD_REGIAO','COD_CICLO'], as_index=False)['QT_VENDA_BRUTO'].mean()\n",
    "df_regiao_qtd = df_regiao_qtd.set_axis(['COD_REGIAO','COD_CICLO','REGIAO_MEDIA_QTD'], axis=1, inplace=False)\n",
    "df_regiao_qtd = df_regiao_qtd.sort_values(by=['REGIAO_MEDIA_QTD'],ascending=False)\n",
    "df_regiao_qtd \n",
    "\n",
    "base_previsao_2 = pd.merge(base_previsao_2,df_regiao_qtd,on= ['COD_REGIAO','COD_CICLO'], how='left' )\n",
    "base_previsao_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLG_CAMPANHA_MKT_B\n",
    "df_flagb_qtd = base_previsao_2.groupby(['FLG_CAMPANHA_MKT_B','COD_CICLO'], as_index=False)['QT_VENDA_BRUTO'].mean()\n",
    "df_flagb_qtd = df_flagb_qtd[df_flagb_qtd['FLG_CAMPANHA_MKT_B'] == 1]\n",
    "df_flagb_qtd = df_flagb_qtd.set_axis(['FLG_CAMPANHA_MKT_B','COD_CICLO','FLAGB_MEDIA_QTD'], axis=1, inplace=False)\n",
    "df_flagb_qtd = df_flagb_qtd.sort_values(by=['COD_CICLO'])\n",
    "df_flagb_qtd\n",
    "\n",
    "base_previsao_2 = pd.merge(base_previsao_2,df_flagb_qtd[['COD_CICLO','FLAGB_MEDIA_QTD']],on= ['COD_CICLO'], how='left' )\n",
    "base_previsao_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLG_CAMPANHA_MKT_A\n",
    "df_flaga_qtd = base_previsao_2.groupby(['FLG_CAMPANHA_MKT_A','COD_CICLO'], as_index=False)['QT_VENDA_BRUTO'].mean()\n",
    "df_flaga_qtd = df_flaga_qtd[df_flaga_qtd['FLG_CAMPANHA_MKT_A'] == 1]\n",
    "df_flaga_qtd = df_flaga_qtd.set_axis(['FLG_CAMPANHA_MKT_A','COD_CICLO','FLAGA_MEDIA_QTD'], axis=1, inplace=False)\n",
    "df_flaga_qtd = df_flaga_qtd.sort_values(by=['COD_CICLO'])\n",
    "df_flaga_qtd\n",
    "\n",
    "base_previsao_2 = pd.merge(base_previsao_2,df_flaga_qtd[['COD_CICLO','FLAGA_MEDIA_QTD']],on= ['COD_CICLO'], how='left' )\n",
    "base_previsao_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_2 = base_previsao_2.drop(['COD_CICLO','COD_MATERIAL','QT_DEVOLUCAO','VL_RECEITA_BRUTA','VL_RECEITA_LIQUIDA','ANO','FLG_CAMPANHA_MKT_A','FLG_CAMPANHA_MKT_B','FLG_CAMPANHA_MKT_C','FLG_CAMPANHA_MKT_D','FLG_CAMPANHA_MKT_E','COD_CANAL','DES_CATEGORIA_MATERIAL','DES_MARCA_MATERIAL','COD_REGIAO'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_2 = base_previsao_2.fillna(0)\n",
    "base_previsao_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_2 = base_previsao_2[['QT_VENDA_BRUTO','N_CAMPANHA','FLG_DATA','MATERIAL_MEDIA_QTD','CANAL_MEDIA_QTD','CATEGORIA_MEDIA_QTD','MARCA_MEDIA_QTD','REGIAO_MEDIA_QTD','FLAGB_MEDIA_QTD','FLAGA_MEDIA_QTD','PCT_DESCONTO','VL_PRECO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "sns.heatmap(base_previsao_2.corr(),cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.2 Regressão - Modelo 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dos dados de treino e teste\n",
    "\n",
    "X6 = base_previsao_2.drop(['QT_VENDA_BRUTO'], axis=1)\n",
    "y6 = base_previsao_2['QT_VENDA_BRUTO']\n",
    "\n",
    "# Utilizando a função train_test_split para dividir os dados em treino e teste\n",
    "X6_training, X6_test, y6_training, y6_test = train_test_split(X6, y6,\n",
    "                                                          test_size=0.25, \n",
    "                                                          shuffle=False)\n",
    "\n",
    "print(\"Conjunto de treino X6:\", X6_training.shape)\n",
    "print(\"Conjunto de treino y6:\", y6_training.shape)\n",
    "print(\"Conjunto de teste  X6:\", X6_test.shape)\n",
    "print(\"Conjunto de teste  y6:\", y6_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor - MODELO 6\n",
    "\n",
    "# criterion default= 'squared_error'\n",
    "modelo_6 = RandomForestRegressor(random_state=seed)\n",
    "\n",
    "# Fitar, ou treinar, o modelo usando o dataset de treino\n",
    "modelo_6.fit(X6_training, y6_training)\n",
    "\n",
    "# Prever todos os resultados no dataset de teste\n",
    "y_pred_6 = modelo_6.predict(X6_test)\n",
    "\n",
    "# Calcular e printar métricas\n",
    "print(\"Mean absolute error (MAE): {:.3f}\".format(mean_absolute_error(y6_test, y_pred_6)))\n",
    "print(\"Mean squared error (MSE): {:.3f}\".format(mean_squared_error(y6_test, y_pred_6)))\n",
    "print(\"Mean absolute percentage error(MAPE): {:.3f}\".format(mean_absolute_percentage_error(y6_test, y_pred_6)))\n",
    "print(\"R² Score: {:.3f}\".format(r2_score(y6_test, y_pred_6)))\n",
    "\n",
    "feature_scores_6 = pd.Series(modelo_6.feature_importances_, index=X6.columns).sort_values(ascending=False)\n",
    "print(feature_scores_6)\n",
    "\n",
    "# Creating a seaborn bar plot\n",
    "sns.barplot(x=feature_scores_6, y=feature_scores_6.index)\n",
    "\n",
    "# Add labels to the graph\n",
    "plt.xlabel('Importância das variáveis')\n",
    "plt.ylabel('Variáveis')\n",
    "\n",
    "# Add title to the graph\n",
    "plt.title(\"Importância das variáveis\")\n",
    "\n",
    "# Visualize the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenhando o gráfico de valores previstos por valores reais\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Quantidade de venda bruta - Previsto e Real',fontsize=20)\n",
    "df_6 = pd.DataFrame({'Real':y6_test,'Previsto':y_pred_6})\n",
    "#df_6.sort_values(by=['Real'],ascending=True,inplace=True)\n",
    "df_6 = df_6.reset_index(drop=True)\n",
    "plt.plot(df_6)\n",
    "plt.legend(['Real','Previsto'],fontsize=20)\n",
    "plt.ylabel('Quantidade de venda bruta',fontsize=20)\n",
    "plt.xlabel('Observações',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.3 Regressão - Modelo 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dos dados de treino e teste\n",
    "\n",
    "X7 = base_previsao_2.drop(['QT_VENDA_BRUTO','FLAGB_MEDIA_QTD','FLAGA_MEDIA_QTD','FLG_DATA','N_CAMPANHA'], axis=1)\n",
    "y7 = base_previsao_2['QT_VENDA_BRUTO']\n",
    "\n",
    "# Utilizando a função train_test_split para dividir os dados em treino e teste (2 pt)\n",
    "X7_training, X7_test, y7_training, y7_test = train_test_split(X7, y7,\n",
    "                                                          test_size=0.25, \n",
    "                                                          shuffle=False)\n",
    "\n",
    "print(\"Conjunto de treino X7:\", X7_training.shape)\n",
    "print(\"Conjunto de treino y7:\", y7_training.shape)\n",
    "print(\"Conjunto de teste  X7:\", X7_test.shape)\n",
    "print(\"Conjunto de teste  y7:\", y7_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor - MODELO 7\n",
    "\n",
    "# criterion default= 'squared_error'\n",
    "modelo_7 = RandomForestRegressor(random_state=seed)\n",
    "\n",
    "# Fitar, ou treinar, o modelo usando o dataset de treino\n",
    "modelo_7.fit(X7_training, y7_training)\n",
    "\n",
    "# Prever todos os resultados no dataset de teste\n",
    "y_pred_7 = modelo_7.predict(X7_test)\n",
    "\n",
    "# Calcular e printar métricas\n",
    "print(\"Mean absolute error (MAE): {:.3f}\".format(mean_absolute_error(y7_test, y_pred_7)))\n",
    "print(\"Mean squared error (MSE): {:.3f}\".format(mean_squared_error(y7_test, y_pred_7)))\n",
    "print(\"Mean absolute percentage error(MAPE): {:.3f}\".format(mean_absolute_percentage_error(y7_test, y_pred_7)))\n",
    "print(\"R² Score: {:.3f}\".format(r2_score(y7_test, y_pred_7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scores_7 = pd.Series(modelo_7.feature_importances_, index=X7.columns).sort_values(ascending=False)\n",
    "print(feature_scores_7)\n",
    "\n",
    "# Creating a seaborn bar plot\n",
    "sns.barplot(x=feature_scores_7, y=feature_scores_7.index)\n",
    "\n",
    "# Add labels to the graph\n",
    "plt.xlabel('Importância das variáveis')\n",
    "plt.ylabel('Variáveis')\n",
    "\n",
    "# Add title to the graph\n",
    "plt.title(\"Importância das variáveis\")\n",
    "\n",
    "# Visualize the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenhando o gráfico de valores previstos por valores reais\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Quantidade de venda bruta - Previsto e Real',fontsize=20)\n",
    "df_7 = pd.DataFrame({'Real':y7_test,'Previsto':y_pred_7})\n",
    "#df_6.sort_values(by=['Real'],ascending=True,inplace=True)\n",
    "df_7 = df_7.reset_index(drop=True)\n",
    "plt.plot(df_7)\n",
    "plt.legend(['Real','Previsto'],fontsize=20)\n",
    "plt.ylabel('Quantidade de venda bruta',fontsize=20)\n",
    "plt.xlabel('Observações',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.4 Regressão - Modelo 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dos dados de treino e teste\n",
    "\n",
    "X8 = base_previsao_2.drop(['QT_VENDA_BRUTO','FLAGB_MEDIA_QTD','FLAGA_MEDIA_QTD','FLG_DATA','N_CAMPANHA'], axis=1)\n",
    "y8 = base_previsao_2['QT_VENDA_BRUTO']\n",
    "\n",
    "# Utilizando a função train_test_split para dividir os dados em treino e teste (2 pt)\n",
    "X8_training, X8_test, y8_training, y8_test = train_test_split(X8, y8,\n",
    "                                                          test_size=0.25, \n",
    "                                                          shuffle=False)\n",
    "\n",
    "print(\"Conjunto de treino X8:\", X8_training.shape)\n",
    "print(\"Conjunto de treino y8:\", y8_training.shape)\n",
    "print(\"Conjunto de teste  X8:\", X8_test.shape)\n",
    "print(\"Conjunto de teste  y8:\", y8_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest com seleção de variáveis e Grid Search\n",
    "\n",
    "# definindo os valores possíveis dos parâmetros a serem testados\n",
    "params_8 = {'n_estimators': [5, 50, 100, 500],\n",
    "          'max_features': [2, 5, 9, 13],\n",
    "          'max_depth': [2, 5, 10, 50],\n",
    "          'min_samples_split': [2, 8, 15, 30],}\n",
    "\n",
    "# criando o objeto do modelo com RandomForestRegressor\n",
    "modelo_8 = RandomForestRegressor(random_state = seed)\n",
    "\n",
    "# criando o objeto do grid search com GridSearchCV\n",
    "grid_search_8 = GridSearchCV(modelo_8 , param_grid=params_8, return_train_score=True) # valor padrão para quebras é 3\n",
    "\n",
    "# treinando o modelo com o grid search\n",
    "grid_search_8.fit(X8_training, y8_training)\n",
    "\n",
    "# imprimindo a melhor combinação de hiperparâmetros\n",
    "print('\\n Melhores hiperparâmetros:')\n",
    "print(grid_search_8.best_params_)\n",
    "\n",
    "# configurando o modelo com a melhor combinação de hiperparâmetros\n",
    "\n",
    "modelo_8.set_params(n_estimators = grid_search_8.best_params_['n_estimators'],\n",
    "                           max_features = grid_search_8.best_params_['max_features'],\n",
    "                           max_depth = grid_search_8.best_params_['max_depth'],\n",
    "                           min_samples_split = grid_search_8.best_params_['min_samples_split'])\n",
    "\n",
    "# treinando um modelo com a melhor combinação de hiperparâmetros\n",
    "modelo_8.fit(X8_training, y8_training)\n",
    "\n",
    "# Prever todos os resultados no dataset de validação\n",
    "y_pred_8 = modelo_8.predict(X8_test)\n",
    "\n",
    "# Melhores hiperparâmetros:\n",
    "#{max_depth': 50, 'max_features': 2, 'min_samples_split': 2, 'n_estimators': 500}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# métricas\n",
    "print(\"Mean absolute error (MAE): {:.3f}\".format(mean_absolute_error(y8_test, y_pred_8)))\n",
    "print(\"Mean squared error (MSE): {:.3f}\".format(mean_squared_error(y8_test, y_pred_8)))\n",
    "print(\"Mean absolute percentage error(MAPE): {:.3f}\".format(mean_absolute_percentage_error(y8_test, y_pred_8)))\n",
    "print(\"R² Score: {:.3f}\".format(r2_score(y8_test, y_pred_8)))\n",
    "\n",
    "feature_scores_8 = pd.Series(modelo_8.feature_importances_, index=X8.columns).sort_values(ascending=False)\n",
    "print(feature_scores_8)\n",
    "\n",
    "# Creating a seaborn bar plot\n",
    "sns.barplot(x=feature_scores_8, y=feature_scores_8.index)\n",
    "\n",
    "# Add labels to the graph\n",
    "plt.xlabel('Importância das variáveis')\n",
    "plt.ylabel('Variáveis')\n",
    "\n",
    "# Add title to the graph\n",
    "plt.title(\"Importância das variáveis\")\n",
    "\n",
    "# Visualize the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenhando o gráfico de valores previstos por valores reais\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Quantidade de venda bruta - Previsto e Real',fontsize=20)\n",
    "df_8 = pd.DataFrame({'Real':y6_test,'Previsto':y_pred_8})\n",
    "df_8 = df_8.reset_index(drop=True)\n",
    "plt.plot(df_8)\n",
    "plt.legend(['Real','Previsto'],fontsize=20)\n",
    "plt.ylabel('Quantidade de venda bruta',fontsize=20)\n",
    "plt.xlabel('Observações',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.5 Comparando os modelos de previsão da quantidade bruta de vendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo 6 - Random Forest com todas as variáveis\n",
    "\n",
    "print(\"Modelo 6 - Mean absolute error (MAE): {:.3f}\".format(mean_absolute_error(y6_test, y_pred_6)))\n",
    "print(\"Modelo 6 - Mean squared error (MSE): {:.3f}\".format(mean_squared_error(y6_test, y_pred_6)))\n",
    "print(\"Modelo 6 - Mean absolute percentage error(MAPE): {:.3f}\".format(mean_absolute_percentage_error(y6_test, y_pred_6)))\n",
    "print(\"Modelo 6 - R² Score: {:.3f}\".format(r2_score(y6_test, y_pred_6)))\n",
    "\n",
    "#modelo 7 - Random Forest com seleção de variáveis\n",
    "\n",
    "print(\"Modelo 7 - Mean absolute error (MAE): {:.3f}\".format(mean_absolute_error(y7_test, y_pred_7)))\n",
    "print(\"Modelo 7 - Mean squared error (MSE): {:.3f}\".format(mean_squared_error(y7_test, y_pred_7)))\n",
    "print(\"Modelo 7 - Mean absolute percentage error(MAPE): {:.3f}\".format(mean_absolute_percentage_error(y7_test, y_pred_7)))\n",
    "print(\"Modelo 7 - R² Score: {:.3f}\".format(r2_score(y7_test, y_pred_7)))\n",
    "\n",
    "#modelo 8 - Random Forest com seleção de variáveis e grid search\n",
    "\n",
    "print(\"Modelo 8 - Mean absolute error (MAE): {:.3f}\".format(mean_absolute_error(y8_test, y_pred_8)))\n",
    "print(\"Modelo 8 - Mean squared error (MSE): {:.3f}\".format(mean_squared_error(y8_test, y_pred_8)))\n",
    "print(\"Modelo 8 - Mean absolute percentage error(MAPE): {:.3f}\".format(mean_absolute_percentage_error(y8_test, y_pred_8)))\n",
    "print(\"Modelo 8 - R² Score: {:.3f}\".format(r2_score(y8_test, y_pred_8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.6 Resultado da previsão da quantidade bruta de venda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo de previsão de vendas campeão foi o modelo 7 (Random Forest com feature selection).\n",
    "\n",
    "O modelo 6 não foi escolhido pelo fato de não utilizar uma técnica de feature selection. E o modelo 8, mesmo com feature \n",
    "selection e grid search, não performou bem, apresentando um MAPE alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Previsão  da receita líquida de venda - Regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.1 Preparação da base de dados - Modelos 9, 10 e 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_valor = base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_valor.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtrar somente o cluster 1\n",
    "aux_mat_2 = df_cluster[df_cluster['CLUSTER'] == 1]\n",
    "aux_mat_2 =  aux_mat_2['COD_MATERIAL'].unique()\n",
    "print(len(aux_mat_2))\n",
    "\n",
    "base_previsao_valor_2 = base_previsao_valor[base_previsao_valor['COD_MATERIAL'].isin(aux_mat_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_valor_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_campanha(arg1):\n",
    "    return arg1[-2:]\n",
    "\n",
    "base_previsao_valor_2['N_CAMPANHA'] = base_previsao_valor_2.COD_CICLO.apply(extrair_campanha)\n",
    "\n",
    "base_previsao_valor_2['N_CAMPANHA'] = base_previsao_valor_2['N_CAMPANHA'].astype('int64')\n",
    "\n",
    "print(base_previsao_valor_2.N_CAMPANHA.unique())\n",
    "\n",
    "base_previsao_valor_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COD_MATERIAL\n",
    "df_material_qtd_2 = base_previsao_valor_2.groupby(['COD_MATERIAL','COD_CICLO'], as_index=False)['VL_RECEITA_LIQUIDA'].mean()\n",
    "df_material_qtd_2  = df_material_qtd_2.set_axis(['COD_MATERIAL','COD_CICLO','MATERIAL_MEDIA_VL'], axis=1, inplace=False)\n",
    "df_material_qtd_2  = df_material_qtd_2.sort_values(by=['MATERIAL_MEDIA_VL'],ascending=False)\n",
    "df_material_qtd_2\n",
    "\n",
    "base_previsao_valor_2 = pd.merge(base_previsao_valor_2,df_material_qtd_2,on= ['COD_MATERIAL','COD_CICLO'], how='left' )\n",
    "base_previsao_valor_2\n",
    "\n",
    "#COD_CANAL\n",
    "df_canal_qtd_2 = base_previsao_valor_2.groupby(['COD_CANAL','COD_CICLO'], as_index=False)['VL_RECEITA_LIQUIDA'].mean()\n",
    "df_canal_qtd_2  = df_canal_qtd_2.set_axis(['COD_CANAL','COD_CICLO','CANAL_MEDIA_VL'], axis=1, inplace=False)\n",
    "df_canal_qtd_2  = df_canal_qtd_2.sort_values(by=['CANAL_MEDIA_VL'],ascending=False)\n",
    "df_canal_qtd_2\n",
    "\n",
    "base_previsao_valor_2 = pd.merge(base_previsao_valor_2,df_canal_qtd_2,on= ['COD_CANAL','COD_CICLO'], how='left' )\n",
    "base_previsao_valor_2\n",
    "\n",
    "#'DES_CATEGORIA_MATERIAL'\n",
    "df_categoria_qtd_2 = base_previsao_valor_2.groupby(['DES_CATEGORIA_MATERIAL','COD_CICLO'], as_index=False)['VL_RECEITA_LIQUIDA'].mean()\n",
    "df_categoria_qtd_2  = df_categoria_qtd_2.set_axis(['DES_CATEGORIA_MATERIAL','COD_CICLO','CATEGORIA_MEDIA_VL'], axis=1, inplace=False)\n",
    "df_categoria_qtd_2  = df_categoria_qtd_2.sort_values(by=['CATEGORIA_MEDIA_VL'],ascending=False)\n",
    "df_categoria_qtd_2\n",
    "\n",
    "base_previsao_valor_2 = pd.merge(base_previsao_valor_2,df_categoria_qtd_2,on= ['DES_CATEGORIA_MATERIAL','COD_CICLO'], how='left' )\n",
    "base_previsao_valor_2\n",
    "\n",
    "#'DES_MARCA_MATERIAL'\n",
    "df_marca_qtd_2 = base_previsao_valor_2.groupby(['DES_MARCA_MATERIAL','COD_CICLO'], as_index=False)['VL_RECEITA_LIQUIDA'].mean()\n",
    "df_marca_qtd_2= df_marca_qtd_2.set_axis(['DES_MARCA_MATERIAL','COD_CICLO','MARCA_MEDIA_VL'], axis=1, inplace=False)\n",
    "df_marca_qtd_2 = df_marca_qtd_2.sort_values(by=['MARCA_MEDIA_VL'],ascending=False)\n",
    "df_marca_qtd_2\n",
    "\n",
    "base_previsao_valor_2 = pd.merge(base_previsao_valor_2,df_marca_qtd_2,on= ['DES_MARCA_MATERIAL','COD_CICLO'], how='left' )\n",
    "base_previsao_valor_2\n",
    "\n",
    "#COD_REGIAO\n",
    "df_regiao_qtd_2 = base_previsao_valor_2.groupby(['COD_REGIAO','COD_CICLO'], as_index=False)['VL_RECEITA_LIQUIDA'].mean()\n",
    "df_regiao_qtd_2 = df_regiao_qtd_2.set_axis(['COD_REGIAO','COD_CICLO','REGIAO_MEDIA_VL'], axis=1, inplace=False)\n",
    "df_regiao_qtd_2 = df_regiao_qtd_2.sort_values(by=['REGIAO_MEDIA_VL'],ascending=False)\n",
    "df_regiao_qtd_2 \n",
    "\n",
    "base_previsao_valor_2 = pd.merge(base_previsao_valor_2,df_regiao_qtd_2,on= ['COD_REGIAO','COD_CICLO'], how='left' )\n",
    "base_previsao_valor_2\n",
    "\n",
    "#FLG_CAMPANHA_MKT_B\n",
    "df_flagb_qtd_2 = base_previsao_valor_2.groupby(['FLG_CAMPANHA_MKT_B','COD_CICLO'], as_index=False)['VL_RECEITA_LIQUIDA'].mean()\n",
    "df_flagb_qtd_2 = df_flagb_qtd_2[df_flagb_qtd_2['FLG_CAMPANHA_MKT_B'] == 1]\n",
    "df_flagb_qtd_2 = df_flagb_qtd_2.set_axis(['FLG_CAMPANHA_MKT_B','COD_CICLO','FLAGB_MEDIA_VL'], axis=1, inplace=False)\n",
    "df_flagb_qtd_2 = df_flagb_qtd_2.sort_values(by=['COD_CICLO'])\n",
    "df_flagb_qtd_2\n",
    "\n",
    "base_previsao_valor_2 = pd.merge(base_previsao_valor_2,df_flagb_qtd_2[['COD_CICLO','FLAGB_MEDIA_VL']],on= ['COD_CICLO'], how='left' )\n",
    "base_previsao_valor_2\n",
    "\n",
    "#FLG_CAMPANHA_MKT_A\n",
    "df_flaga_qtd_2 = base_previsao_valor_2.groupby(['FLG_CAMPANHA_MKT_A','COD_CICLO'], as_index=False)['VL_RECEITA_LIQUIDA'].mean()\n",
    "df_flaga_qtd_2 = df_flaga_qtd_2[df_flaga_qtd_2['FLG_CAMPANHA_MKT_A'] == 1]\n",
    "df_flaga_qtd_2 = df_flaga_qtd_2.set_axis(['FLG_CAMPANHA_MKT_A','COD_CICLO','FLAGA_MEDIA_VL'], axis=1, inplace=False)\n",
    "df_flaga_qtd_2 = df_flaga_qtd_2.sort_values(by=['COD_CICLO'])\n",
    "df_flaga_qtd_2\n",
    "\n",
    "base_previsao_valor_2 = pd.merge(base_previsao_valor_2,df_flaga_qtd_2[['COD_CICLO','FLAGA_MEDIA_VL']],on= ['COD_CICLO'], how='left' )\n",
    "base_previsao_valor_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_valor_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_valor_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_valor_2 = base_previsao_valor_2.drop(['COD_CICLO','COD_MATERIAL','QT_DEVOLUCAO','QT_VENDA_BRUTO','VL_RECEITA_BRUTA','ANO','FLG_CAMPANHA_MKT_A','FLG_CAMPANHA_MKT_B','FLG_CAMPANHA_MKT_C','FLG_CAMPANHA_MKT_D','FLG_CAMPANHA_MKT_E','COD_CANAL','DES_CATEGORIA_MATERIAL','DES_MARCA_MATERIAL','COD_REGIAO'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_valor_2 = base_previsao_valor_2.fillna(0)\n",
    "base_previsao_valor_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_valor_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_valor_2 = base_previsao_valor_2[['VL_RECEITA_LIQUIDA','N_CAMPANHA','FLG_DATA','MATERIAL_MEDIA_VL','CANAL_MEDIA_VL','CATEGORIA_MEDIA_VL','MARCA_MEDIA_VL','REGIAO_MEDIA_VL','FLAGB_MEDIA_VL','FLAGA_MEDIA_VL','PCT_DESCONTO','VL_PRECO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_previsao_valor_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz de correlação\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(base_previsao_valor_2.corr(),cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.2 Regressão - Modelo 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dos dados de treino e teste\n",
    "\n",
    "X9 = base_previsao_valor_2.drop(['VL_RECEITA_LIQUIDA'], axis=1)\n",
    "y9 = base_previsao_valor_2['VL_RECEITA_LIQUIDA']\n",
    "\n",
    "# Utilizando a função train_test_split para dividir os dados em treino e teste\n",
    "X9_training, X9_test, y9_training, y9_test = train_test_split(X9, y9,\n",
    "                                                          test_size=0.25, \n",
    "                                                          shuffle=False)\n",
    "\n",
    "print(\"Conjunto de treino X9:\", X9_training.shape)\n",
    "print(\"Conjunto de treino y9:\", y9_training.shape)\n",
    "print(\"Conjunto de teste  X9:\", X9_test.shape)\n",
    "print(\"Conjunto de teste  y9:\", y9_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor - MODELO 9\n",
    "\n",
    "# criterion default= 'squared_error'\n",
    "modelo_9 = RandomForestRegressor(random_state=seed)\n",
    "\n",
    "# Fitar, ou treinar, o modelo usando o dataset de treino\n",
    "modelo_9.fit(X9_training, y9_training)\n",
    "\n",
    "# Prever todos os resultados no dataset de teste\n",
    "y_pred_9 = modelo_9.predict(X9_test)\n",
    "\n",
    "# Calcular e printar métricas\n",
    "print(\"Mean absolute error (MAE): {:.3f}\".format(mean_absolute_error(y9_test, y_pred_9)))\n",
    "print(\"Mean squared error (MSE): {:.3f}\".format(mean_squared_error(y9_test, y_pred_9)))\n",
    "print(\"Mean absolute percentage error(MAPE): {:.3f}\".format(mean_absolute_percentage_error(y9_test, y_pred_9)))\n",
    "print(\"R² Score: {:.3f}\".format(r2_score(y9_test, y_pred_9)))\n",
    "\n",
    "feature_scores_9 = pd.Series(modelo_9.feature_importances_, index=X9.columns).sort_values(ascending=False)\n",
    "print(feature_scores_9)\n",
    "\n",
    "# Creating a seaborn bar plot\n",
    "sns.barplot(x=feature_scores_9, y=feature_scores_9.index)\n",
    "\n",
    "# Add labels to the graph\n",
    "plt.xlabel('Importância das variáveis')\n",
    "plt.ylabel('Variáveis')\n",
    "\n",
    "# Add title to the graph\n",
    "plt.title(\"Importância das variáveis\")\n",
    "\n",
    "# Visualize the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenhando o gráfico de valores previstos por valores reais\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Valor de receita líquida - Previsto e Real',fontsize=20)\n",
    "df_9 = pd.DataFrame({'Real':y9_test,'Previsto':y_pred_9})\n",
    "df_9 = df_9.reset_index(drop=True)\n",
    "plt.plot(df_9)\n",
    "plt.legend(['Real','Previsto'],fontsize=20)\n",
    "plt.ylabel('Valor de receita líquida',fontsize=20)\n",
    "plt.xlabel('Observações',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.3 Regressão - Modelo 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dos dados de treino e teste\n",
    "\n",
    "X10 = base_previsao_valor_2.drop(['VL_RECEITA_LIQUIDA','FLAGB_MEDIA_VL','FLAGA_MEDIA_VL','FLG_DATA','N_CAMPANHA'], axis=1)\n",
    "y10 = base_previsao_valor_2['VL_RECEITA_LIQUIDA']\n",
    "\n",
    "# Utilizando a função train_test_split para dividir os dados em treino e teste \n",
    "X10_training, X10_test, y10_training, y10_test = train_test_split(X10, y10,\n",
    "                                                          test_size=0.25, \n",
    "                                                          shuffle=False)\n",
    "print(\"Conjunto de treino X10:\", X10_training.shape)\n",
    "print(\"Conjunto de treino y10:\", y10_training.shape)\n",
    "print(\"Conjunto de teste  X10:\", X10_test.shape)\n",
    "print(\"Conjunto de teste  y10:\", y10_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor - MODELO 10\n",
    "\n",
    "# criterion default= 'squared_error'\n",
    "modelo_10 = RandomForestRegressor(random_state=seed)\n",
    "\n",
    "# Fitar, ou treinar, o modelo usando o dataset de treino\n",
    "modelo_10.fit(X10_training, y10_training)\n",
    "\n",
    "# Prever todos os resultados no dataset de teste\n",
    "y_pred_10 = modelo_10.predict(X10_test)\n",
    "\n",
    "# Calcular e printar métricas\n",
    "print(\"Mean absolute error (MAE): {:.3f}\".format(mean_absolute_error(y10_test, y_pred_10)))\n",
    "print(\"Mean squared error (MSE): {:.3f}\".format(mean_squared_error(y10_test, y_pred_10)))\n",
    "print(\"Mean absolute percentage error(MAPE): {:.3f}\".format(mean_absolute_percentage_error(y10_test, y_pred_10)))\n",
    "print(\"R² Score: {:.3f}\".format(r2_score(y10_test, y_pred_10)))\n",
    "\n",
    "feature_scores_10 = pd.Series(modelo_10.feature_importances_, index=X10.columns).sort_values(ascending=False)\n",
    "print(feature_scores_10)\n",
    "\n",
    "# Creating a seaborn bar plot\n",
    "sns.barplot(x=feature_scores_10, y=feature_scores_10.index)\n",
    "\n",
    "# Add labels to the graph\n",
    "plt.xlabel('Importância das variáveis')\n",
    "plt.ylabel('Variáveis')\n",
    "\n",
    "# Add title to the graph\n",
    "plt.title(\"Importância das variáveis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenhando o gráfico de valores previstos por valores reais\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Valor de receita líquida - Previsto e Real',fontsize=20)\n",
    "df_10 = pd.DataFrame({'Real':y10_test,'Previsto':y_pred_10})\n",
    "df_10 = df_10.reset_index(drop=True)\n",
    "plt.plot(df_10)\n",
    "plt.legend(['Real','Previsto'],fontsize=20)\n",
    "plt.ylabel('Valor de receita líquida',fontsize=20)\n",
    "plt.xlabel('Observações',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.4 Regressão - Modelo 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dos dados de treino e teste\n",
    "\n",
    "X11 = base_previsao_valor_2.drop(['VL_RECEITA_LIQUIDA','FLAGB_MEDIA_VL','FLAGA_MEDIA_VL','FLG_DATA','N_CAMPANHA'], axis=1)\n",
    "y11 = base_previsao_valor_2['VL_RECEITA_LIQUIDA']\n",
    "\n",
    "# Utilizando a função train_test_split para dividir os dados em treino e teste\n",
    "X11_training, X11_test, y11_training, y11_test = train_test_split(X11, y11,\n",
    "                                                          test_size=0.25, \n",
    "                                                          shuffle=False)\n",
    "\n",
    "print(\"Conjunto de treino X11:\", X11_training.shape)\n",
    "print(\"Conjunto de treino y11:\", y11_training.shape)\n",
    "print(\"Conjunto de teste  X11:\", X11_test.shape)\n",
    "print(\"Conjunto de teste  y11:\", y11_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest com seleção de variáveis e Grid Search\n",
    "\n",
    "# definindo os valores possíveis dos parâmetros a serem testados\n",
    "params_11 = {'n_estimators': [5, 50, 100, 500],\n",
    "          'max_features': [2, 5, 9, 13],\n",
    "          'max_depth': [2, 5, 10, 50],\n",
    "          'min_samples_split': [2, 8, 15, 30],}\n",
    "\n",
    "# criando o objeto do modelo com RandomForestRegressor\n",
    "modelo_11 = RandomForestRegressor(random_state = seed)\n",
    "\n",
    "# criando o objeto do grid search com GridSearchCV\n",
    "grid_search_11 = GridSearchCV(modelo_11 , param_grid=params_11, return_train_score=True) # valor padrão para quebras é 3\n",
    "\n",
    "# treinando o modelo com o grid search\n",
    "grid_search_11.fit(X11_training, y11_training)\n",
    "\n",
    "# imprimindo a melhor combinação de hiperparâmetros\n",
    "print('\\n Melhores hiperparâmetros:')\n",
    "print(grid_search_11.best_params_)\n",
    "\n",
    "# configurando o modelo com a melhor combinação de hiperparâmetros\n",
    "modelo_11.set_params(n_estimators = grid_search_11.best_params_['n_estimators'],\n",
    "                           max_features = grid_search_11.best_params_['max_features'],\n",
    "                           max_depth = grid_search_11.best_params_['max_depth'],\n",
    "                           min_samples_split = grid_search_11.best_params_['min_samples_split'])\n",
    "\n",
    "# treinando um modelo com a melhor combinação de hiperparâmetros\n",
    "modelo_11.fit(X11_training, y11_training)\n",
    "\n",
    "# Prever todos os resultados no dataset de validação\n",
    "y_pred_11 = modelo_11.predict(X11_test)\n",
    "\n",
    "# Melhores hiperparâmetros:\n",
    "#{'max_depth': 50, 'max_features': 5, 'min_samples_split': 2, 'n_estimators': 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# métricas\n",
    "print(\"Mean absolute error (MAE): {:.3f}\".format(mean_absolute_error(y11_test, y_pred_11)))\n",
    "print(\"Mean squared error (MSE): {:.3f}\".format(mean_squared_error(y11_test, y_pred_11)))\n",
    "print(\"Mean absolute percentage error(MAPE): {:.3f}\".format(mean_absolute_percentage_error(y11_test, y_pred_11)))\n",
    "print(\"R² Score: {:.3f}\".format(r2_score(y11_test, y_pred_11)))\n",
    "\n",
    "feature_scores_11 = pd.Series(modelo_11.feature_importances_, index=X11.columns).sort_values(ascending=False)\n",
    "print(feature_scores_11)\n",
    "\n",
    "# Creating a seaborn bar plot\n",
    "sns.barplot(x=feature_scores_11, y=feature_scores_11.index)\n",
    "\n",
    "# Add labels to the graph\n",
    "plt.xlabel('Importância das variáveis')\n",
    "plt.ylabel('Variáveis')\n",
    "\n",
    "# Add title to the graph\n",
    "plt.title(\"Importância das variáveis\")\n",
    "\n",
    "# Visualize the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenhando o gráfico de valores previstos por valores reais\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Valor de receita líquida - Previsto e Real',fontsize=20)\n",
    "df_11 = pd.DataFrame({'Real':y11_test,'Previsto':y_pred_11})\n",
    "df_11 = df_11.reset_index(drop=True)\n",
    "plt.plot(df_11)\n",
    "plt.legend(['Real','Previsto'],fontsize=20)\n",
    "plt.ylabel('Valor de receita líquida',fontsize=20)\n",
    "plt.xlabel('Observações',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.5 Comparando os modelos de previsão da receita líquida de vendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo 9 - Random Forest com todas as variáveis\n",
    "\n",
    "print(\"Modelo 9 - Mean absolute error (MAE): {:.3f}\".format(mean_absolute_error(y9_test, y_pred_9)))\n",
    "print(\"Modelo 9 - Mean squared error (MSE): {:.3f}\".format(mean_squared_error(y9_test, y_pred_9)))\n",
    "print(\"Modelo 9 - Mean absolute percentage error(MAPE): {:.3f}\".format(mean_absolute_percentage_error(y9_test, y_pred_9)))\n",
    "print(\"Modelo 9 - R² Score: {:.3f}\".format(r2_score(y9_test, y_pred_9)))\n",
    "\n",
    "#modelo 10 - Random Forest com seleção de variáveis\n",
    "\n",
    "print(\"Modelo 10 - Mean absolute error (MAE): {:.3f}\".format(mean_absolute_error(y10_test, y_pred_10)))\n",
    "print(\"Modelo 10 - Mean squared error (MSE): {:.3f}\".format(mean_squared_error(y10_test, y_pred_10)))\n",
    "print(\"Modelo 10 - Mean absolute percentage error(MAPE): {:.3f}\".format(mean_absolute_percentage_error(y10_test, y_pred_10)))\n",
    "print(\"Modelo 10 - R² Score: {:.3f}\".format(r2_score(y10_test, y_pred_10)))\n",
    "\n",
    "#modelo 11 - Random Forest com seleção de variáveis\n",
    "\n",
    "print(\"Modelo 11 - Mean absolute error (MAE): {:.3f}\".format(mean_absolute_error(y11_test, y_pred_11)))\n",
    "print(\"Modelo 11 - Mean squared error (MSE): {:.3f}\".format(mean_squared_error(y11_test, y_pred_11)))\n",
    "print(\"Modelo 11 - Mean absolute percentage error(MAPE): {:.3f}\".format(mean_absolute_percentage_error(y11_test, y_pred_11)))\n",
    "print(\"Modelo 11 - R² Score: {:.3f}\".format(r2_score(y11_test, y_pred_11)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.6 Resultados da previsão de receita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo campeão foi o modelo 10 por apresentar o maior coeficiente de correlação. Alem disso, foi treinado com as variáveis \n",
    "selecionadas pelo modelo Random Forest Regression.\n",
    "\n",
    "O modelo 1 não passou por nenhum método de seleção de variáveis e o modelo 11, apesar de ter seus hiperparâmetros otimizados\n",
    "pelo grid search, apresentou o maior MAPE. Devido a essas informações, os modelos não foram escolhidos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previsões da quantidade bruta de vendas e da receita líquida para os materias do cluster 3 são importantes\n",
    "para conhecermos o comportamento da venda, além disso, traz benefícios como:\n",
    "\n",
    "- Controle de estoque (Maior acuracidade e menos custos com estoque excessivo).\n",
    "- Com a previsão é possível encontrar pontos de maior venda e elaborar ações de marketing eficientes.\n",
    "- Traz a possibilidade de preparar a equipe de vendas para uma alta demanda.\n",
    "- Possibilita gerar expectativas corretas sobre o faturamento esperado.\n",
    "- Ajuda a empresa a conhecer melhor o seu público-alvo e direcionar uma abordagem de vendas mais assertiva."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
